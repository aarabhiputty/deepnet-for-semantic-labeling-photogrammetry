{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "import torch.nn.init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "LABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] \n",
    "WINDOW_SIZE = (256, 256) \n",
    "IN_CHANNELS = 5 \n",
    "BATCH_SIZE = 10 \n",
    "N_CLASSES = len(LABELS) \n",
    "WEIGHTS = torch.ones(N_CLASSES) \n",
    "CACHE = True \n",
    "BASE_LR = 0.01\n",
    "END_LR = 0.1\n",
    "WEIGHT_DECAY = 0.0001\n",
    "EPOCH_SIZE = 10000\n",
    "CURR_EP = 0\n",
    "#PRETRAIN_MODEL = \"../input/unet101-2/Unet101_2_epoch35\"\n",
    "\n",
    "MAIN_FOLDER = \"../input/potsdamvaihingen/\" \n",
    "DATA_FOLDER = MAIN_FOLDER + '3_ortho_irrg/3_Ortho_IRRG/top_potsdam_{}_IRRG.tif'\n",
    "DSM_FOLDER = MAIN_FOLDER + '1_dsm/1_DSM/dsm_potsdam_0{}.tif'\n",
    "NDSM_FOLDER = MAIN_FOLDER + '1_dsm_normalisation/1_DSM_normalisation/dsm_potsdam_0{}_normalized_lastools.jpg'\n",
    "LABEL_FOLDER = MAIN_FOLDER + '5_labels_for_participants/5_Labels_for_participants/top_potsdam_{}_label.tif'\n",
    "ERODED_FOLDER = MAIN_FOLDER + '5_labels_for_participants_no_boundary/5_Labels_for_participants_no_Boundary/top_potsdam_{}_label_noBoundary.tif'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a38d9cdbb61b0a0465dcf5ecc6cafeb59bfeaae9"
   },
   "outputs": [],
   "source": [
    "palette = {0 : (255, 255, 255), # Impervious surfaces (white)\n",
    "           1 : (0, 0, 255),     # Buildings (blue)\n",
    "           2 : (0, 255, 255),   # Low vegetation (cyan)\n",
    "           3 : (0, 255, 0),     # Trees (green)\n",
    "           4 : (255, 255, 0),   # Cars (yellow)\n",
    "           5 : (255, 0, 0),     # Clutter (red)\n",
    "           6 : (0, 0, 0)}       # Undefined (black)\n",
    "\n",
    "invert_palette = {v: k for k, v in palette.items()}\n",
    "\n",
    "def convert_to_color(arr_2d, palette=palette):\n",
    "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
    "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = arr_2d == c\n",
    "        arr_3d[m] = i\n",
    "\n",
    "    return arr_3d\n",
    "\n",
    "def convert_from_color(arr_3d, palette=invert_palette):\n",
    "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
    "        arr_2d[m] = i\n",
    "\n",
    "    return arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3b27f2ea65458b7cc384fa7e79bc56dba91789c2"
   },
   "outputs": [],
   "source": [
    "def get_random_pos(img, window_shape):\n",
    "    \"\"\" Extract of 2D random patch of shape window_shape in the image \"\"\"\n",
    "    w, h = window_shape\n",
    "    W, H = img.shape[-2:]\n",
    "    x1 = random.randint(0, W - w - 1)\n",
    "    x2 = x1 + w\n",
    "    y1 = random.randint(0, H - h - 1)\n",
    "    y2 = y1 + h\n",
    "    return x1, x2, y1, y2\n",
    "\n",
    "def CrossEntropy2d(input, target, weight=None):\n",
    "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
    "    dim = input.dim()\n",
    "    if dim == 2:\n",
    "        return F.cross_entropy(input, target, weight, size_average)\n",
    "    elif dim == 4:\n",
    "        output = input.view(input.size(0),input.size(1), -1)\n",
    "        output = torch.transpose(output,1,2).contiguous()\n",
    "        output = output.view(-1,output.size(2))\n",
    "        target = target.view(-1)\n",
    "        return F.cross_entropy(output, target,weight)\n",
    "    else:\n",
    "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
    "\n",
    "def accuracy(input, target):\n",
    "    return 100 * float(np.count_nonzero(input == target)) / target.size\n",
    "\n",
    "def sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            yield x, y, window_size[0], window_size[1]\n",
    "            \n",
    "def count_sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Count the number of windows in an image \"\"\"\n",
    "    c = 0\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def grouper(n, iterable):\n",
    "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "\n",
    "def metrics(predictions, gts, label_values=LABELS):\n",
    "    cm = confusion_matrix(\n",
    "            gts,\n",
    "            predictions,\n",
    "            range(len(label_values)))\n",
    "    \n",
    "    print(\"Confusion matrix :\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    # Compute global accuracy\n",
    "    total = sum(sum(cm))\n",
    "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
    "    accuracy *= 100 / float(total)\n",
    "    print(\"{} pixels processed\".format(total))\n",
    "    print(\"Total accuracy : {}%\".format(accuracy))\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    # Compute F1 score\n",
    "    F1Score = np.zeros(len(label_values))\n",
    "    for i in range(len(label_values)):\n",
    "        try:\n",
    "            F1Score[i] = 2. * cm[i,i] / (np.sum(cm[i,:]) + np.sum(cm[:,i]))\n",
    "        except:\n",
    "            # Ignore exception if there is no element in class i for test set\n",
    "            pass\n",
    "    print(\"F1Score :\")\n",
    "    for l_id, score in enumerate(F1Score):\n",
    "        print(\"{}: {}\".format(label_values[l_id], score))\n",
    "\n",
    "    print(\"---\")\n",
    "        \n",
    "    # Compute kappa coefficient\n",
    "    total = np.sum(cm)\n",
    "    pa = np.trace(cm) / float(total)\n",
    "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / float(total*total)\n",
    "    kappa = (pa - pe) / (1 - pe);\n",
    "    print(\"Kappa: \" + str(kappa))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "806064dbf5367ecca8b42065a42e3a36285ccc56"
   },
   "outputs": [],
   "source": [
    "class ISPRS_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_ids, dsm_ids, data_files=DATA_FOLDER, label_files=LABEL_FOLDER,\n",
    "                dsm_files=DSM_FOLDER, ndsm_files=NDSM_FOLDER,\n",
    "                cache=False, augmentation=True):\n",
    "        super(ISPRS_dataset, self).__init__()\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.cache = cache\n",
    "        \n",
    "        # List of files\n",
    "        self.data_files = [DATA_FOLDER.format(id) for id in train_ids]\n",
    "        self.dsm_files = [DSM_FOLDER.format(id) for id in dsm_ids]\n",
    "        self.ndsm_files = [NDSM_FOLDER.format(id) for id in dsm_ids]\n",
    "        self.label_files = [LABEL_FOLDER.format(id) for id in train_ids]\n",
    "        \n",
    "        # Initialize cache dicts\n",
    "        self.data_cache_ = {}\n",
    "        self.label_cache_ = {}\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return EPOCH_SIZE\n",
    "    \n",
    "    @classmethod\n",
    "    def data_augmentation(cls, *arrays, flip=True, mirror=True):\n",
    "        will_flip, will_mirror = False, False\n",
    "        if flip and random.random() < 0.5:\n",
    "            will_flip = True\n",
    "        if mirror and random.random() < 0.5:\n",
    "            will_mirror = True\n",
    "        \n",
    "        results = []\n",
    "        for array in arrays:\n",
    "            if will_flip:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[::-1, :]\n",
    "                else:\n",
    "                    array = array[:, ::-1, :]\n",
    "            if will_mirror:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[:, ::-1]\n",
    "                else:\n",
    "                    array = array[:, :, ::-1]\n",
    "            results.append(np.copy(array))\n",
    "            \n",
    "        return tuple(results)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Pick a random image\n",
    "        random_idx = random.randint(0, len(self.data_files) - 1)\n",
    "        \n",
    "        # If the tile hasn't been loaded yet, put in cache\n",
    "        if random_idx in self.data_cache_.keys():\n",
    "            data = self.data_cache_[random_idx]\n",
    "        else:\n",
    "            # Data is normalized in [0, 1]\n",
    "            im = np.dstack((io.imread(self.data_files[random_idx]), io.imread(self.dsm_files[random_idx])))\n",
    "            im = np.dstack((im, io.imread(self.ndsm_files[random_idx])))\n",
    "            data = np.asarray(im.transpose((2,0,1)), dtype='float32')\n",
    "            if self.cache:\n",
    "                self.data_cache_[random_idx] = data\n",
    "            \n",
    "        if random_idx in self.label_cache_.keys():\n",
    "            label = self.label_cache_[random_idx]\n",
    "        else: \n",
    "            # Labels are converted from RGB to their numeric values\n",
    "            label = np.asarray(convert_from_color(io.imread(self.label_files[random_idx])), dtype='int64')\n",
    "            if self.cache:\n",
    "                self.label_cache_[random_idx] = label\n",
    "\n",
    "        # Get a random patch\n",
    "        x1, x2, y1, y2 = get_random_pos(data, WINDOW_SIZE)\n",
    "        data_p = 1/255 * data[:, x1:x2,y1:y2]\n",
    "        label_p = label[x1:x2,y1:y2]\n",
    "        \n",
    "        # Data augmentation\n",
    "        data_p, label_p = self.data_augmentation(data_p, label_p)\n",
    "\n",
    "        # Return the torch.Tensor values\n",
    "        return (torch.from_numpy(data_p),\n",
    "                torch.from_numpy(label_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d261eb0cdff5db818d4b6f4c131cfe7155ca1b33"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Helper module that consists of a Conv -> BN -> ReLU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.with_nonlinearity = with_nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.with_nonlinearity:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bridge(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the middle layer of the UNet which just consists of some\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            ConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bridge(x)\n",
    "\n",
    "\n",
    "class UpBlockForUNetWithResNet101(nn.Module):\n",
    "    \"\"\"\n",
    "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "                 upsampling_method=\"conv_transpose\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if up_conv_in_channels == None:\n",
    "            up_conv_in_channels = in_channels\n",
    "        if up_conv_out_channels == None:\n",
    "            up_conv_out_channels = out_channels\n",
    "\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            )\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, down_x):\n",
    "        \"\"\"\n",
    "        :param up_x: this is the output from the previous up block\n",
    "        :param down_x: this is the output from the down block\n",
    "        :return: upsampled feature map\n",
    "        \"\"\"\n",
    "        x = self.upsample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetWithResnet101Encoder(nn.Module):\n",
    "    DEPTH = 6\n",
    "\n",
    "    def __init__(self, n_classes=N_CLASSES):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet.resnet101(pretrained=True)\n",
    "        resnet.conv1 = nn.Conv2d(IN_CHANNELS, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        down_blocks = []\n",
    "        up_blocks = []\n",
    "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "        self.input_pool = list(resnet.children())[3]\n",
    "        for bottleneck in list(resnet.children()):\n",
    "            if isinstance(bottleneck, nn.Sequential):\n",
    "                down_blocks.append(bottleneck)\n",
    "        self.down_blocks = nn.ModuleList(down_blocks)\n",
    "        self.bridge = Bridge(2048, 2048)\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(2048, 1024))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(1024, 512))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(512, 256))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(in_channels=128 + 64, out_channels=128,\n",
    "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(in_channels=64 + 5, out_channels=64,\n",
    "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(up_blocks)\n",
    "\n",
    "        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x, with_output_feature_map=False):\n",
    "        pre_pools = dict()\n",
    "        pre_pools[f\"layer_0\"] = x\n",
    "        x = self.input_block(x)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.input_pool(x)\n",
    "\n",
    "        for i, block in enumerate(self.down_blocks, 2):\n",
    "            x = block(x)\n",
    "            if i == (UNetWithResnet101Encoder.DEPTH - 1):\n",
    "                continue\n",
    "            pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "        x = self.bridge(x)\n",
    "\n",
    "        for i, block in enumerate(self.up_blocks, 1):\n",
    "            key = f\"layer_{UNetWithResnet101Encoder.DEPTH - 1 - i}\"\n",
    "            x = block(x, pre_pools[key])\n",
    "        output_feature_map = x\n",
    "        x = self.out(x)\n",
    "        del pre_pools\n",
    "        if with_output_feature_map:\n",
    "            return x, output_feature_map\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "3023f2190d56f65234d0df55d6516a290e636340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /tmp/.torch/models/resnet101-5d3b4d8f.pth\n",
      "178728960it [00:08, 21704885.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNetWithResnet101Encoder(\n",
       "  (input_block): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (input_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bridge): Bridge(\n",
       "    (bridge): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(2048, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(69, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNetWithResnet101Encoder()\n",
    "#net.load_state_dict(torch.load(PRETRAIN_MODEL)['model_state_dict'])\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3094824b16216e371f3194dfd8a82e3fd98bdb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles for training :  ['3_11', '5_10', '6_7', '6_8', '6_9', '7_7', '7_8', '7_9', '7_10', '7_12']\n"
     ]
    }
   ],
   "source": [
    "train_ids = ['3_11','5_10','6_7','6_8','6_9','7_7','7_8','7_9','7_10','7_12']\n",
    "# valid: ['3_12','4_10','4_11',4_12','5_11','6_12',]\n",
    "# train 1: ['2_10','2_11','2_12','3_10','5_12','6_10','6_11','7_10','7_11','7_12']\n",
    "# train 2: ['3_11','5_10','6_7','6_8','6_9','7_7','7_8','7_9','7_10','7_12']\n",
    "dsm_ids =   ['3_11','5_10','6_07','6_08','6_09','7_07','7_08','7_09','7_10','7_12']\n",
    "\n",
    "print(\"Tiles for training : \", train_ids)\n",
    "train_set = ISPRS_dataset(train_ids, dsm_ids, cache=CACHE)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cyclical_lr(stepsize, min_lr, max_lr):\n",
    "\n",
    "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
    "    scaler = lambda x: 1.\n",
    "\n",
    "    # Lambda function to calculate the LR\n",
    "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
    "\n",
    "    # Additional function to see where on the cycle we are\n",
    "    def relative(it, stepsize):\n",
    "        cycle = math.floor(1 + it / (2 * stepsize))\n",
    "        x = abs(it / stepsize - 2 * cycle + 1)\n",
    "        return max(0, (1 - x)) * scaler(cycle)\n",
    "\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "649b42279a018c320cc93ed54cdff7c15d9a8db1"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "#optimizer.load_state_dict(torch.load(PRETRAIN_MODEL)['optimizer_state_dict'])\n",
    "\n",
    "step_size = 5*len(train_loader)\n",
    "clr = cyclical_lr(step_size, min_lr=BASE_LR, max_lr=END_LR)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e1c376825ae35c6e061aa74a9f97fcd7567e649b"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "def train(net, optimizer, epochs, scheduler=scheduler, weights=WEIGHTS):\n",
    "    losses = np.zeros(1000000)\n",
    "    mean_losses = np.zeros(100000000)\n",
    "    weights = weights.cuda()\n",
    "    iter_ = 0\n",
    "    \n",
    "    for e in range(1, epochs + 1):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        net.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = CrossEntropy2d(output, target, weight=weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses[iter_] = loss.item()\n",
    "            mean_losses[iter_] = np.mean(losses[max(0,iter_-100):iter_])\n",
    "            gc.collect()\n",
    "            if iter_ % 100 == 0:\n",
    "                clear_output()\n",
    "                #rgb = np.asarray(255 * np.transpose(data.data.cpu().numpy()[0],(1,2,0)), dtype='uint8')\n",
    "                pred = np.argmax(output.data.cpu().numpy()[0], axis=0)\n",
    "                gt = target.data.cpu().numpy()[0]\n",
    "                print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}'.format(\n",
    "                    e, epochs, batch_idx, len(train_loader),\n",
    "                    100. * batch_idx / len(train_loader), loss.item(), accuracy(pred, gt)))\n",
    "                plt.plot(mean_losses[:iter_]) and plt.show()\n",
    "                fig = plt.figure()\n",
    "                fig.add_subplot(131)\n",
    "                plt.imshow(convert_to_color(gt))\n",
    "                plt.title('Ground truth')\n",
    "                fig.add_subplot(132)\n",
    "                plt.title('Prediction')\n",
    "                plt.imshow(convert_to_color(pred))\n",
    "                plt.show()\n",
    "            iter_ += 1\n",
    "            \n",
    "            del(data, target, loss)\n",
    "            \n",
    "        if e in [25, 35]:\n",
    "            # We validate with the largest possible stride for faster computing\n",
    "            gc.collect()\n",
    "            torch.save({\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, 'Unet101_2_epoch{}'.format(e+CURR_EP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "0b7eed3e5a288ebe5c343957b908ddf7b862d7a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 35/35) [900/1000 (90%)]\tLoss: 0.229351\tAccuracy: 89.0045166015625\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(net, optimizer, 35, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
