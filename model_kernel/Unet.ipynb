{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "import torch.nn.init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "LABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] \n",
    "WINDOW_SIZE = (256, 256) \n",
    "IN_CHANNELS = 5 \n",
    "BATCH_SIZE = 8 \n",
    "N_CLASSES = len(LABELS) \n",
    "WEIGHTS = torch.ones(N_CLASSES) \n",
    "CACHE = True \n",
    "BASE_LR = 0.01\n",
    "END_LR = 0.1\n",
    "WEIGHT_DECAY = 0.0001\n",
    "EPOCH_SIZE = 10000\n",
    "CURR_EP = 0\n",
    "PRETRAIN_MODEL = \"../input/unet101-epoch90/Unet101_epoch90\"\n",
    "\n",
    "MAIN_FOLDER = \"../input/potsdamvaihingen/\" \n",
    "DATA_FOLDER = MAIN_FOLDER + '3_ortho_irrg/3_Ortho_IRRG/top_potsdam_{}_IRRG.tif'\n",
    "DSM_FOLDER = MAIN_FOLDER + '1_dsm/1_DSM/dsm_potsdam_0{}.tif'\n",
    "NDSM_FOLDER = MAIN_FOLDER + '1_dsm_normalisation/1_DSM_normalisation/dsm_potsdam_0{}_normalized_lastools.jpg'\n",
    "LABEL_FOLDER = MAIN_FOLDER + '5_labels_for_participants/5_Labels_for_participants/top_potsdam_{}_label.tif'\n",
    "ERODED_FOLDER = MAIN_FOLDER + '5_labels_for_participants_no_boundary/5_Labels_for_participants_no_Boundary/top_potsdam_{}_label_noBoundary.tif'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a38d9cdbb61b0a0465dcf5ecc6cafeb59bfeaae9"
   },
   "outputs": [],
   "source": [
    "palette = {0 : (255, 255, 255), # Impervious surfaces (white)\n",
    "           1 : (0, 0, 255),     # Buildings (blue)\n",
    "           2 : (0, 255, 255),   # Low vegetation (cyan)\n",
    "           3 : (0, 255, 0),     # Trees (green)\n",
    "           4 : (255, 255, 0),   # Cars (yellow)\n",
    "           5 : (255, 0, 0),     # Clutter (red)\n",
    "           6 : (0, 0, 0)}       # Undefined (black)\n",
    "\n",
    "invert_palette = {v: k for k, v in palette.items()}\n",
    "\n",
    "def convert_to_color(arr_2d, palette=palette):\n",
    "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
    "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = arr_2d == c\n",
    "        arr_3d[m] = i\n",
    "\n",
    "    return arr_3d\n",
    "\n",
    "def convert_from_color(arr_3d, palette=invert_palette):\n",
    "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
    "        arr_2d[m] = i\n",
    "\n",
    "    return arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3b27f2ea65458b7cc384fa7e79bc56dba91789c2"
   },
   "outputs": [],
   "source": [
    "def get_random_pos(img, window_shape):\n",
    "    \"\"\" Extract of 2D random patch of shape window_shape in the image \"\"\"\n",
    "    w, h = window_shape\n",
    "    W, H = img.shape[-2:]\n",
    "    x1 = random.randint(0, W - w - 1)\n",
    "    x2 = x1 + w\n",
    "    y1 = random.randint(0, H - h - 1)\n",
    "    y2 = y1 + h\n",
    "    return x1, x2, y1, y2\n",
    "\n",
    "def CrossEntropy2d(input, target, weight=None):\n",
    "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
    "    dim = input.dim()\n",
    "    if dim == 2:\n",
    "        return F.cross_entropy(input, target, weight, size_average)\n",
    "    elif dim == 4:\n",
    "        output = input.view(input.size(0),input.size(1), -1)\n",
    "        output = torch.transpose(output,1,2).contiguous()\n",
    "        output = output.view(-1,output.size(2))\n",
    "        target = target.view(-1)\n",
    "        return F.cross_entropy(output, target,weight)\n",
    "    else:\n",
    "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
    "\n",
    "def accuracy(input, target):\n",
    "    return 100 * float(np.count_nonzero(input == target)) / target.size\n",
    "\n",
    "def sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            yield x, y, window_size[0], window_size[1]\n",
    "            \n",
    "def count_sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Count the number of windows in an image \"\"\"\n",
    "    c = 0\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def grouper(n, iterable):\n",
    "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "\n",
    "def metrics(predictions, gts, label_values=LABELS):\n",
    "    cm = confusion_matrix(\n",
    "            gts,\n",
    "            predictions,\n",
    "            range(len(label_values)))\n",
    "    \n",
    "    print(\"Confusion matrix :\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    # Compute global accuracy\n",
    "    total = sum(sum(cm))\n",
    "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
    "    accuracy *= 100 / float(total)\n",
    "    print(\"{} pixels processed\".format(total))\n",
    "    print(\"Total accuracy : {}%\".format(accuracy))\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    # Compute F1 score\n",
    "    F1Score = np.zeros(len(label_values))\n",
    "    for i in range(len(label_values)):\n",
    "        try:\n",
    "            F1Score[i] = 2. * cm[i,i] / (np.sum(cm[i,:]) + np.sum(cm[:,i]))\n",
    "        except:\n",
    "            # Ignore exception if there is no element in class i for test set\n",
    "            pass\n",
    "    print(\"F1Score :\")\n",
    "    for l_id, score in enumerate(F1Score):\n",
    "        print(\"{}: {}\".format(label_values[l_id], score))\n",
    "\n",
    "    print(\"---\")\n",
    "        \n",
    "    # Compute kappa coefficient\n",
    "    total = np.sum(cm)\n",
    "    pa = np.trace(cm) / float(total)\n",
    "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / float(total*total)\n",
    "    kappa = (pa - pe) / (1 - pe);\n",
    "    print(\"Kappa: \" + str(kappa))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "806064dbf5367ecca8b42065a42e3a36285ccc56"
   },
   "outputs": [],
   "source": [
    "class ISPRS_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_ids, dsm_ids, data_files=DATA_FOLDER, label_files=LABEL_FOLDER,\n",
    "                dsm_files=DSM_FOLDER, ndsm_files=NDSM_FOLDER,\n",
    "                cache=False, augmentation=True):\n",
    "        super(ISPRS_dataset, self).__init__()\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.cache = cache\n",
    "        \n",
    "        # List of files\n",
    "        self.data_files = [DATA_FOLDER.format(id) for id in train_ids]\n",
    "        self.dsm_files = [DSM_FOLDER.format(id) for id in dsm_ids]\n",
    "        self.ndsm_files = [NDSM_FOLDER.format(id) for id in dsm_ids]\n",
    "        self.label_files = [LABEL_FOLDER.format(id) for id in train_ids]\n",
    "        \n",
    "        # Initialize cache dicts\n",
    "        self.data_cache_ = {}\n",
    "        self.label_cache_ = {}\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        return EPOCH_SIZE\n",
    "    \n",
    "    @classmethod\n",
    "    def data_augmentation(cls, *arrays, flip=True, mirror=True):\n",
    "        will_flip, will_mirror = False, False\n",
    "        if flip and random.random() < 0.5:\n",
    "            will_flip = True\n",
    "        if mirror and random.random() < 0.5:\n",
    "            will_mirror = True\n",
    "        \n",
    "        results = []\n",
    "        for array in arrays:\n",
    "            if will_flip:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[::-1, :]\n",
    "                else:\n",
    "                    array = array[:, ::-1, :]\n",
    "            if will_mirror:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[:, ::-1]\n",
    "                else:\n",
    "                    array = array[:, :, ::-1]\n",
    "            results.append(np.copy(array))\n",
    "            \n",
    "        return tuple(results)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Pick a random image\n",
    "        random_idx = random.randint(0, len(self.data_files) - 1)\n",
    "        \n",
    "        # If the tile hasn't been loaded yet, put in cache\n",
    "        if random_idx in self.data_cache_.keys():\n",
    "            data = self.data_cache_[random_idx]\n",
    "        else:\n",
    "            # Data is normalized in [0, 1]\n",
    "            im = np.dstack((io.imread(self.data_files[random_idx]), io.imread(self.dsm_files[random_idx])))\n",
    "            im = np.dstack((im, io.imread(self.ndsm_files[random_idx])))\n",
    "            data = np.asarray(im.transpose((2,0,1)), dtype='float32')\n",
    "            if self.cache:\n",
    "                self.data_cache_[random_idx] = data\n",
    "            \n",
    "        if random_idx in self.label_cache_.keys():\n",
    "            label = self.label_cache_[random_idx]\n",
    "        else: \n",
    "            # Labels are converted from RGB to their numeric values\n",
    "            label = np.asarray(convert_from_color(io.imread(self.label_files[random_idx])), dtype='int64')\n",
    "            if self.cache:\n",
    "                self.label_cache_[random_idx] = label\n",
    "\n",
    "        # Get a random patch\n",
    "        x1, x2, y1, y2 = get_random_pos(data, WINDOW_SIZE)\n",
    "        data_p = 1/255 * data[:, x1:x2,y1:y2]\n",
    "        label_p = label[x1:x2,y1:y2]\n",
    "        \n",
    "        # Data augmentation\n",
    "        data_p, label_p = self.data_augmentation(data_p, label_p)\n",
    "\n",
    "        # Return the torch.Tensor values\n",
    "        return (torch.from_numpy(data_p),\n",
    "                torch.from_numpy(label_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d261eb0cdff5db818d4b6f4c131cfe7155ca1b33"
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Helper module that consists of a Conv -> BN -> ReLU\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, padding=1, kernel_size=3, stride=1, with_nonlinearity=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, padding=padding, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.with_nonlinearity = with_nonlinearity\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if self.with_nonlinearity:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bridge(nn.Module):\n",
    "    \"\"\"\n",
    "    This is the middle layer of the UNet which just consists of some\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.bridge = nn.Sequential(\n",
    "            ConvBlock(in_channels, out_channels),\n",
    "            ConvBlock(out_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bridge(x)\n",
    "\n",
    "\n",
    "class UpBlockForUNetWithResNet101(nn.Module):\n",
    "    \"\"\"\n",
    "    Up block that encapsulates one up-sampling step which consists of Upsample -> ConvBlock -> ConvBlock\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, up_conv_in_channels=None, up_conv_out_channels=None,\n",
    "                 upsampling_method=\"conv_transpose\"):\n",
    "        super().__init__()\n",
    "\n",
    "        if up_conv_in_channels == None:\n",
    "            up_conv_in_channels = in_channels\n",
    "        if up_conv_out_channels == None:\n",
    "            up_conv_out_channels = out_channels\n",
    "\n",
    "        if upsampling_method == \"conv_transpose\":\n",
    "            self.upsample = nn.ConvTranspose2d(up_conv_in_channels, up_conv_out_channels, kernel_size=2, stride=2)\n",
    "        elif upsampling_method == \"bilinear\":\n",
    "            self.upsample = nn.Sequential(\n",
    "                nn.Upsample(mode='bilinear', scale_factor=2),\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1)\n",
    "            )\n",
    "        self.conv_block_1 = ConvBlock(in_channels, out_channels)\n",
    "        self.conv_block_2 = ConvBlock(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, up_x, down_x):\n",
    "        \"\"\"\n",
    "        :param up_x: this is the output from the previous up block\n",
    "        :param down_x: this is the output from the down block\n",
    "        :return: upsampled feature map\n",
    "        \"\"\"\n",
    "        x = self.upsample(up_x)\n",
    "        x = torch.cat([x, down_x], 1)\n",
    "        x = self.conv_block_1(x)\n",
    "        x = self.conv_block_2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetWithResnet101Encoder(nn.Module):\n",
    "    DEPTH = 6\n",
    "\n",
    "    def __init__(self, n_classes=N_CLASSES):\n",
    "        super().__init__()\n",
    "        resnet = torchvision.models.resnet.resnet101(pretrained=True)\n",
    "        resnet.conv1 = nn.Conv2d(IN_CHANNELS, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        down_blocks = []\n",
    "        up_blocks = []\n",
    "        self.input_block = nn.Sequential(*list(resnet.children()))[:3]\n",
    "        self.input_pool = list(resnet.children())[3]\n",
    "        for bottleneck in list(resnet.children()):\n",
    "            if isinstance(bottleneck, nn.Sequential):\n",
    "                down_blocks.append(bottleneck)\n",
    "        self.down_blocks = nn.ModuleList(down_blocks)\n",
    "        self.bridge = Bridge(2048, 2048)\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(2048, 1024))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(1024, 512))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(512, 256))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(in_channels=128 + 64, out_channels=128,\n",
    "                                                    up_conv_in_channels=256, up_conv_out_channels=128))\n",
    "        up_blocks.append(UpBlockForUNetWithResNet101(in_channels=64 + 5, out_channels=64,\n",
    "                                                    up_conv_in_channels=128, up_conv_out_channels=64))\n",
    "\n",
    "        self.up_blocks = nn.ModuleList(up_blocks)\n",
    "\n",
    "        self.out = nn.Conv2d(64, n_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x, with_output_feature_map=False):\n",
    "        pre_pools = dict()\n",
    "        pre_pools[f\"layer_0\"] = x\n",
    "        x = self.input_block(x)\n",
    "        pre_pools[f\"layer_1\"] = x\n",
    "        x = self.input_pool(x)\n",
    "\n",
    "        for i, block in enumerate(self.down_blocks, 2):\n",
    "            x = block(x)\n",
    "            if i == (UNetWithResnet101Encoder.DEPTH - 1):\n",
    "                continue\n",
    "            pre_pools[f\"layer_{i}\"] = x\n",
    "\n",
    "        x = self.bridge(x)\n",
    "\n",
    "        for i, block in enumerate(self.up_blocks, 1):\n",
    "            key = f\"layer_{UNetWithResnet101Encoder.DEPTH - 1 - i}\"\n",
    "            x = block(x, pre_pools[key])\n",
    "        output_feature_map = x\n",
    "        x = self.out(x)\n",
    "        del pre_pools\n",
    "        if with_output_feature_map:\n",
    "            return x, output_feature_map\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "3023f2190d56f65234d0df55d6516a290e636340"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /tmp/.torch/models/resnet101-5d3b4d8f.pth\n",
      "178728960it [00:01, 116420554.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNetWithResnet101Encoder(\n",
       "  (input_block): Sequential(\n",
       "    (0): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (input_pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (down_blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (bridge): Bridge(\n",
       "    (bridge): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up_blocks): ModuleList(\n",
       "    (0): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(2048, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (3): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (4): UpBlockForUNetWithResNet101(\n",
       "      (upsample): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (conv_block_1): ConvBlock(\n",
       "        (conv): Conv2d(69, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (conv_block_2): ConvBlock(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (out): Conv2d(64, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = UNetWithResnet101Encoder()\n",
    "net.load_state_dict(torch.load(PRETRAIN_MODEL)['model_state_dict'])\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "3094824b16216e371f3194dfd8a82e3fd98bdb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles for training :  ['3_11', '5_10', '6_7', '6_8', '6_9', '7_7', '7_8', '7_9', '7_10', '7_12']\n"
     ]
    }
   ],
   "source": [
    "train_ids = ['3_11','5_10','6_7','6_8','6_9','7_7','7_8','7_9','7_10','7_12']\n",
    "# valid: ['3_12','4_10','4_11',4_12','5_11','6_12',]\n",
    "# train 1: ['2_10','2_11','2_12','3_10','5_12','6_10','6_11','7_10','7_11','7_12']\n",
    "# train 2: ['3_11','5_10','6_7','6_8','6_9','7_7','7_8','7_9','7_10','7_12']\n",
    "dsm_ids =   ['3_11','5_10','6_07','6_08','6_09','7_07','7_08','7_09','7_10','7_12']\n",
    "\n",
    "print(\"Tiles for training : \", train_ids)\n",
    "train_set = ISPRS_dataset(train_ids, dsm_ids, cache=CACHE)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def cyclical_lr(stepsize, min_lr, max_lr):\n",
    "\n",
    "    # Scaler: we can adapt this if we do not want the triangular CLR\n",
    "    scaler = lambda x: 1.\n",
    "\n",
    "    # Lambda function to calculate the LR\n",
    "    lr_lambda = lambda it: min_lr + (max_lr - min_lr) * relative(it, stepsize)\n",
    "\n",
    "    # Additional function to see where on the cycle we are\n",
    "    def relative(it, stepsize):\n",
    "        cycle = math.floor(1 + it / (2 * stepsize))\n",
    "        x = abs(it / stepsize - 2 * cycle + 1)\n",
    "        return max(0, (1 - x)) * scaler(cycle)\n",
    "\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "649b42279a018c320cc93ed54cdff7c15d9a8db1"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
    "optimizer.load_state_dict(torch.load(PRETRAIN_MODEL)['optimizer_state_dict'])\n",
    "\n",
    "step_size = 5*len(train_loader)\n",
    "clr = cyclical_lr(step_size, min_lr=BASE_LR, max_lr=END_LR)\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, [clr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "e1c376825ae35c6e061aa74a9f97fcd7567e649b"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "def train(net, optimizer, epochs, scheduler=scheduler, weights=WEIGHTS):\n",
    "    losses = np.zeros(1000000)\n",
    "    mean_losses = np.zeros(100000000)\n",
    "    weights = weights.cuda()\n",
    "    iter_ = 0\n",
    "    \n",
    "    for e in range(1, epochs + 1):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        net.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = CrossEntropy2d(output, target, weight=weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses[iter_] = loss.item()\n",
    "            mean_losses[iter_] = np.mean(losses[max(0,iter_-100):iter_])\n",
    "            gc.collect()\n",
    "            if iter_ % 100 == 0:\n",
    "                clear_output()\n",
    "                #rgb = np.asarray(255 * np.transpose(data.data.cpu().numpy()[0],(1,2,0)), dtype='uint8')\n",
    "                pred = np.argmax(output.data.cpu().numpy()[0], axis=0)\n",
    "                gt = target.data.cpu().numpy()[0]\n",
    "                print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}'.format(\n",
    "                    e, epochs, batch_idx, len(train_loader),\n",
    "                    100. * batch_idx / len(train_loader), loss.item(), accuracy(pred, gt)))\n",
    "                plt.plot(mean_losses[:iter_]) and plt.show()\n",
    "                fig = plt.figure()\n",
    "                fig.add_subplot(131)\n",
    "                plt.imshow(convert_to_color(gt))\n",
    "                plt.title('Ground truth')\n",
    "                fig.add_subplot(132)\n",
    "                plt.title('Prediction')\n",
    "                plt.imshow(convert_to_color(pred))\n",
    "                plt.show()\n",
    "            iter_ += 1\n",
    "            \n",
    "            del(data, target, loss)\n",
    "            \n",
    "        if e in [20, 35]:\n",
    "            # We validate with the largest possible stride for faster computing\n",
    "            gc.collect()\n",
    "            torch.save({\n",
    "                'model_state_dict': net.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, 'Unet101_2_epoch{}'.format(e+CURR_EP))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "0b7eed3e5a288ebe5c343957b908ddf7b862d7a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 35/35) [1200/1250 (96%)]\tLoss: 0.792763\tAccuracy: 55.79376220703125\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQQAAACRCAYAAAAl1MZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF69JREFUeJztnXuwXVV9xz8/EqhjAUNIDCEJRCXTaewDuHcqFIeWDnSAijCVOoBDUgtkOtoWBpkaqp3aVtHS4oPWMiJQHgKWKgXqYC0yUkcQhnsVEUIDgQGTEBICBcOjCvrrH3udk3X33Y+19tmPtc9dnztn7jlr7732Ovu31nf/1m+ttY+oKpFIJAKwR9cFiEQi4RAFIRKJDImCEIlEhkRBiEQiQ6IgRCKRIVEQIpHIkCgIDSAiT4rIsS2f82Mi8qU2zzlOiMhKEVERmW8+f11E1lbI5yAReUlE5tVfyubppSCIyGkicp+IvCwiO8z7D4iIdF22MkTkahH5+Ih5/LaIbKmrTH3CiO2rptFtN9dz77rPo6onqOo1juUZir+q/khV91bVn9VdpjbonSCIyIeAzwF/DxwALAH+GDgK2CvnmN6o9eAOFSnkJFXdGzgcmAQ+am+UhN7V7SBQ1d68gDcBLwPvKdnvauAy4Haz/7Hm2GuBZ4GnSCrRHmb/jwFfso5fCSgw33y+C/hb4G5gF/BfwCJr/zNNns8BHwGeBI7NKNc64DXgp8BLwH+Y9CeBDwMPAj8B5pvzH5L6Th8HfhF4Ffi5yeMl4EDzHW4y33EX8DAw2bXNGqgDM64tyY3ha8ZGnzA2ehU4xNj8SmAbsNVcv3nmuHnAPwA7gSeAD2bY/GzrPOcAj5hru4FEjK4zdnjV2OHPM+rOgcBtwPPAJuAcK8/gbNY3FT0S+AXgVod9zyCpIPsA3wH+kaSCvBX4LWAN8H6Pc59h9n8ziSdyAYCIrCYRnzNJjL8/sDwrA1W9HLgeuFgTt/Ika/PpwO8BC1T19bxCqOrLwAnA0yaPvVX1abP53cCXgQUklfCfPL5f7xCRFcCJwPdN0pkkorsPiUBfDbxOIg6HAb8LnG32PQd4l0mfBE4tOM8fkDTeNcC+JNf5OVU9E/gRxmNR1YszDv8ysIWkbpwKXCQiv2NtD8pmfROERcBOu8GIyD0i8oLpVx5t7Xurqt6tqj8nuSufBlyoqrtU9UngEpIK5Mq/qOqjqvoqiaofatJPBb6mqt9W1Z8Af0ly1/DlUlXdbPKvyndU9XZN+q/XAb8+Ql4hc4uIvEAi9P8NXGTSr1bVh039WEgiFuep6suqugP4DEk9AHgv8FlzzZ8HPllwvrNJRPx+Tdikqk+VFdII1lHAh1X1/1T1AeAKEmEZEJTN+tZffQ5YJCLzB6Kgqr8JYIJstsBttt4vAvYkuWsMeApY5nHuZ6z3rwCDQNaB9rlU9WURec4j3wGby3cpJV3GN9jXaow4RVW/aSeYeLJ9DQ8msfk2K9a8h7XPgan9ixr4CuDxCuU8EHheVXelzjNpfQ7KZn3zEL5L0sc+2WFfexnnThIv4WAr7SCSfiUkcYY3WtsO8CjTNpIKA4CIvJGk2+BSrqL0VwrKFJeoZmNfl80kdWWRqi4wr31V9e1m+wy7kdSHPDYDb3M4Z5qngYUisk/qPFtz9u+cXgmCqr4A/DXwzyJyqojsIyJ7iMihJMG2vON+RuLmf8IcczBwPjAYt38AONqMIb8JuNCjWF8B3iUi7xSRvYC/ofi6bieJY5TxAHCGiMwTkeNJ4h52HvubskYyUNVtJMHfS0RkX1NP3iYig+t4E/BnIrJcRPYD1hdkdwVwgYhMmBGMQ0wdggJ7qupm4B7gkyLyBhH5NeAsdte74OiVIACYwM35JBHd7eb1BZIo/T0Fh/4piSfwBEnf8wbgKpPnHcC/kkT5p0mi1q7leZgkQn0DyV3nf0mCSHlcCaw2cY9bCvY7FzgJeAF4HzDcV1X/B7gReMLkc6BreecYa0gCwBtI7PIVYKnZ9kXgG8APgO8BN+dloqr/RhKgvoFkNOAWkhgFJLGHjxo7XJBx+OkkIw9PA/8O/FW6uxMSYoY/IpFIpH8eQiQSaY5GBEFEjheRjSKySUSK+maRnhFtO97U3mUw04QfBY4j6UvfD5yuqhtqPVGkdaJtx58mPITfADap6hOq+lOSWVguw4SR8Im2HXOamJi0jJkTPrYA7yg6YNGiRbpy5cpKJ5uudFQzuTTG9ESbJ9upqotzNnrZVmSRJgH2Aiamd3+/CWOHVr9vBhOp+jA9MTttVFr/joV2HdLZTEURWUcy75yDDjqIqampavnUU5pacmkMqXZtKp6sdEpu4dGWXZM5OCVln85574oa20lG17doW3ofe7+pVH2Qqdlpo9KqTcHVrk10GbYycwbYcjJmZqnq5ao6qaqTixeXClckDEpta9sVGrKryu7XjDRmvrL2T7+y8nZJy0M0W4CKRCkgmhCE+4FVIvIWM3PvNJJVXJH+055tnRthlgLY2zzPOWi46Qbs2qBtr8Q+xkdUOqT2LoOqvi4if0IyC2wecJWZzRfpOY3bNt1o0i5/ZqMapJU12PR2SW3LyFt0dpfCpWGnRcH+HLgwNBJDUNXbSR5O0hNyKkRkFlVtqwq5D7grayROjUhwXzc2SCvoHuSJky+21wHBi0KcqRhpjIkJQIXhVJey/ntjCMWCX1KWvG5E0f6+xwRCFIQh/TJcX9Ci6zpDGFxjAXn75Jdgdh7g7BGmG3Ze0HDWacP1AoqIgjCDKArd4HLd0/tkCYNQ7g14UtWbKRKNgL2GKAizCNdYfUetv5mkG1yet+ASOKxhtCFN1mhB1dGI1rtLfvTtEWotYRs1L4odrlFDRzIFII/Btiw7pPPxsUk63xyKGrxvnCBgIRgQPYRSiu46vv3ZyGzSDbys0bg2KpcgoscQYl5A1PWO7zJrMgCiINRCFIc8ZnsDeYFGyXmf99l1KDIvzTOomP6cJQxZBN5FSNNbQag5dFQjURTKSOzmKqAdWTk9mlA4OYriO3/gXoFN72IIYYpAGsf+6Rwg7Q3IrE9Fk8LquH4OefjML8haDJWH3d3oiSj0xkMI1yMooh+VoC2yOg9BkDc7sYh0A/eZcBWwOPRCEPonBBFIVjPP7rFXGQloARdRKNqWNeIw6HYMPIsexBOCFoR+egVpwr0bNM0EWR0C1+HbEa1fehf2DAS73vk7m55dD8EKQv8uZSSPsZNEnwBiz4QhWEEYr0o0Xt/GFbcHIDV0bWY0QssTyGvMPu59WQN3DTa2hcf5gh5liIuS+4+b/YpmH9aMbyPPGyHIe1ZDmfcQuLcQrIcwfsxNL2FAN9/eNUaQtyLS5dB+dQnKCNpDiIyPiLg1Gd8RCNfZiln7DtLt/OzNFa991VGKQIgeQrCMjxi44/qdfTuTZSMZJSMaPWjIhXiIWxAegj1ePd64VOS5KAS+1LHAKQ9joyrPUmyDhmc9Rg+hdYr6tXNdDHwbXUuLygaNcNSGWEdDbniWYxAewtxkrjf+LMpWQboeW/Vu3nC3YSAsoXgbGUQPIRIIeY2kCQ+gYzGOaxkikTyyAnqj3kFdhxpHGG6sSuDDlLHLEGmQQbjYt8G5uv9FeRctQRdrnyJRCLfhNkX0ECINMviF46Jhv7wG7bK4yWfSkUv63BOANNFDiLRAUePz9SAGQ7dZqyZ98kmvdbD/p8+VPjRjAZMPAccQoiBEGqbsTly2HDrrIaxZeaaFwnfikofH0GQMoImHsao4X47YZYg0THo2YFUxyMs7a//AXX+XB610RPQQIh2RvvPbAb70c5aKXHp7v1HOn6ZDUalbFMR9qncUhEjD5FXGtJuetQgpr8GXNeYyocgTlqJjWqLj328o7TKIyFUiskNEHrLSForIHSLymPm/n0kXEblURDaJyIMicniThY+Mwh8BbwZ+xUp7HmBVvXZ1iQkM0vO6E7aHkNWYi7a7liuLDhplHVOkR8AlhnA1cHwqbT1wp6quAu40nwFOAFaZ1zrgsnqKOS44rq5rhT8E/jOV9imAXd3btSy24HKMy35F3kXO9qzfahgjSgVBVb+NuXVYnAxcY95fA5xipV+rCfcCC0RkaV2F7S95AtClOBwNLEyl3QrwnPlQk13Td/B0vGBAXhyBjH1dyRtGLJoZWWKLuhY6BUrVUYYlqrrNvH8GWGLeLwM2W/ttMWmzEJF1IjIlIlM8+2zFYoSMb2MPwWvYDvCa+VCjXcu6ApTsl/W5Knnn9Lj+VX7HoSeMPOyoqpVWn6jq5ao6qaqTLF48ajECY5SKEka3on67Nr3ku+hapb9KDUvQx1AMoLogbB+4jOb/DpO+FVhh7bfcpM0h6q4obVa8JQB7Qt12rTqD0Ic6BCcvYDme3YMsqgrCbcBa834tpvNp0teYqPQRwItW12IO0Pe7xrsB9jcfOrCra+Pzvc5Vl1an50OMPy7DjjcC3wV+SUS2iMhZJOHo40TkMeBY8xngduAJYBPwReADjZQ6SBqezmq9VBn5ddppp3PAAUcyf/5Gli1bzhVXXMnOnesB9m3frr534Sp3bJcuRRNLsfNOKbNfASBJV7HjQkxOKlNTXRdjBNo1ZvoXletERKZVdbKWvIKxax0Ln7K21Yj9JCX7tx6ynrBUtrgqKy/c7BrXMkTGmKLFUAFS9IMwWZR5FukfkXEgTl3uI5IycABeni/us+tHPYtN0arG9ChER/ED1/kNPj8n57GWIXoIPWQc5sR002P2jVMEeqEbXC0ZPYRIZMbsyLzZjT75DPLyKIE5dIbzZzfu9O9EZKXnZu7+PIQoCLXQjgMcaRp7anU63SbP1vaxeXUir8titursHmGyS86dv+Zfmo5dhkhkiGsAsspCqqxztXAT8exCBCII010XoAYC7W/OaXznFLhMUio7Jt3Q82Y75p+r9hhx337bMaFHw0MRD7q0a50LpMpiC0XdRvuZD/WUJy0amd2MCgTiIQzoez884Mh0ZzR9PUKoM8VxgS7qxVAwPE8dkIcwTsQgYzt0fY3LRhVcvKOcbo1qZpa53Ym0x5CR5kIUhMYIURTCKU/ZPdU/l752ORXNCDAqguSIQnYuCaNaOEBB6KthI+Xstm390hRCnXG9Cey+Dlqyv2+AMW931+sdWAwhMt6E6DXVhab+DygLNIZFFIQeMmOuifMtJJQKGMKdPBQEKbkebVstUEEIpfKOSqz8o9FUPWi7flU/X9s1KFBBiESgv4KaFzLNDh6OTn0CF7AgjIuXUC+BPFinY0a9CG0ITR1zD9o3dsCCEBkPmqjUffIc2hKfeghcEMbhdlifsfrpHZRF3dv6Ul1evPw6IGhOYLGbWa8BzkOIjDez5/OrQ7R9NLqc21J07vRTmmYeVdfZfQhaEJI7YvZXkl49NqyO8ffxGMPPC6Kl0+sViC7rSt7zEXaXSbNWJunuCVxFk43K1mf6zmAMWhCKyLyI9E0oXBmP7+QTUR/s26zn0DZ5D2ApJt2wfadA+RB4DMGfPKHonqoVu64GoY6vZqg6vKaml90fRnnmgrVXTj32tZDvlQtWEEYJoI2PKPT/7ljcoN2FqD+iUL/NXDuL6YhEFYkPVhDGl/438uoUeSPlnkp/RMGPrG6unTbKt/Z9UFtvYwhlqEjA8YS8UE9JeYP9PnlMI8PlvVW8o9lVufkRiW4oq6uu33hw1QZX3DeoGKSH0M/x9iq499/73QS6jp/0H98mUXVMamw9BGjPS2jiDOOiiaNfm9lVe1y9BFfK/K28UQgXgvMQ+uYdjEu1FPMXJrOvctvxBNcA3Si+UPNjPeW4/Bz8ChH5lohsEJGHReRck75QRO4QkcfM//1MuojIpSKySUQeFJHDm/4S40jTFWTz5s0cc8wxrF69Gnm7wOeGm+bVZ9eJBkreHlnXv2iSsWZ8drFf1bEn10ev+Eini4fwOvAhVV0NHAF8UERWA+uBO1V1FXCn+QxwArDKvNYBl3mUJ9IS8+fP565L7uKRDY/AvcDngQ0ALCVIu4bji1UR6bxj7LTseYwzt7uOGvjsa1MqCKq6TVW/Z97vAh4BlgEnA9eY3a4BTjHvTwau1YR7gQUistSlME10F8Kdk9AtS5cuhcE9fh/gl4GtACygZruOK77C4Ptg9rJpyYP/yUusbl8VKUjwiiGIyErgMOA+YImqbjObngGWmPfLgM3WYVtMWjqvdSIyJSJTB033L3bQHxwqyJPA94F3ADC/Lrvy7LOjFb1DmvRHXJY6ueSx+yWp7kme31GOsyCIyN7AV4HzVPXHMwqn6u1FqerlqjqpqpOLfQ6MjIAwSyBeAt4DfBbYd+beo9p1YrGPZbta39c8Ln36LMnO/yZi7V/PVOkBToIgInuSiMH1qnqzSd4+cBnN/x0mfSuwwjp8OQNntCPqDs6FEA2uhddIxOB9wO8PU19v367V1zlkpY5K3XbNmhOQdvnTFF0RNZO9ileOaqV66jLKIMCVwCOq+mlr023AWvN+LXCrlb7GRKWPAF60XNDOKVva4xsh7iuqwFkksYPzZ2x6gdbtOvqVrsumbdrb1VNoE5eJSUcBZwI/FJEHTNpfAJ8CbhKRs4CngPeabbcDJwKbgFeA99daYl96N923He6+G7gO+FXgUJN4EQDbgOPqsGsbv+ltT4uW1JSdqsN5bVJlRqHLRPCq30U0gAYzKaJTTWVew/fzXHEQGEU90czEaVWdrOXMk5OqU3VZdnZpXWcr5g3huexXlUH+ZXMGss7ttrLRL3YgIk52DW6mYt2MNggTGY2mfYRiSRjnLl9TjLUghLvacS5RhxTnewehCX365pP2FFzoMiw6toubohh0z+6Jy1WWP9vHplMGPe/sPF3XHLQhJq5dBp+ylHcXql/vsfQQohiUE9qdNZsiMcima8unz+/qIfjNeHTYW6p1lsfOQ4hiECo+znN2JZ45EWd2PlWnETdN0QPk7H3Sfs9IZVRbON1zGisPIYqBG916B3U4z+Haucq1rd8eav33C62OjSBEMcgjPeu9PaZzlz+np1CXu7cDN1nHSAyyfB2fmIMMj5htX0n9udLrLkMUAT/afwDK9IjhxN1u70AOir7BKOeqg1EDlbZAlOeVP8oimVLjVrIgPITpCb8HaYhqFANPunka0oQ5tz95gbM6rF7nMio3/6ac+mrzaJPug/EQ7AaefobBXGj8WQ22Lve420ej2dOKB58ltXUmM4cVw7N9nVcz7RV0TTCCYDMXBMAmr8EO0kcRhnCekzho5CmxH25Lp1b7zlUmAlXJP32OUK7yqAQpCCHRtKFdGmwVYQhHCLLwH5W3h+VcqNKL9hWTOmMWvmsf/HJ2L2UUhA7xbbR1eAzdY3cH/CprW0N6WYvZ8vIJWXYT/OrKnBKEOoNJXRL23b8IzfkfNiFMYmor1yBGGeYmfW3UkT6RBCvn4MSkSCQykyr+VxAPSBGRXcDGrsuRwyJgZ9eFyKCpch2sqrU89zbatRKd2jWUGMLGup7SUzciMhVi2UItV4poV0+6LlfsMkQikSFRECKRyJBQBOHyrgtQQKhlC7VcNiGXMdSydVquIIKKkUgkDELxECKRSABEQYhEIkM6FwQROV5ENorIJhFZ3/K5rxKRHSLykJW2UETuEJHHzP/9TLqIyKWmnA+KyOH5OddSthUi8i0R2SAiD4vIuSGVz6H8ndnVnD9I2wZvV1Xt7AXMAx4H3grsBfwAWN3i+Y8GDgcestIuBtab9+uBvzPvTwS+TjLn+AjgvobLthQ43LzfB3gUWB1K+UK2a8i2Dd2unVQY6+IcCXzD+nwhcGHLZViZqjQbgaWW8Taa918ATs/ar6Vy3gocF2r5QrNrX2wbml277jIsAzZbn7eYtC5Zort/1fgZYIl531lZRWQlcBhwX4jlyyCkstgEde1CtGvXghA0mkhyp+OyIrI38FXgPFX9sb0thPL1la6vXah27VoQtgIrrM/LTVqXbBeRpQDm/w6T3npZRWRPkkpzvareHFr5CgipLDZBXLuQ7dq1INwPrBKRt4jIXsBpwG0dl+k2YK15v5akjzdIX2OivkcAL1ouXu2IiABXAo+o6qdDK18JIdoVArh2wdu17UBPRlDlRJJI6+PAR1o+943ANuA1kr7ZWcD+wJ3AY8A3gYVmXwE+b8r5Q2Cy4bK9k8RtfBB4wLxODKV8Ids1ZNuGbtc4dTkSiQzpussQiUQCIgpCJBIZEgUhEokMiYIQiUSGREGIRCJDoiBEIpEhURAikciQ/wdL+PDGZEO2KQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(net, optimizer, 35, scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
