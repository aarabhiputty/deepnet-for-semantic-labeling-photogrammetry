{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# imports and stuff\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import itertools\n",
    "# Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Torch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "import torch.nn.init\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "WINDOW_SIZE = (224, 224) # Patch size\n",
    "STRIDE = 32 # Stride for testing\n",
    "IN_CHANNELS = 5 # Number of input channels (e.g. RGB)\n",
    "FOLDER = \"../input/potsdamvaihingen/\" # Replace with your \"/path/to/the/ISPRS/dataset/folder/\"\n",
    "BATCH_SIZE = 8 # Number of samples in a mini-batch\n",
    "\n",
    "LABELS = [\"roads\", \"buildings\", \"low veg.\", \"trees\", \"cars\", \"clutter\"] # Label names\n",
    "N_CLASSES = len(LABELS) # Number of classes\n",
    "WEIGHTS = torch.ones(N_CLASSES) # Weights for class balancing\n",
    "CACHE = True # Store the dataset in-memory\n",
    "\n",
    "DATASET = 'Potsdam'\n",
    "\n",
    "if DATASET == 'Potsdam':\n",
    "    MAIN_FOLDER = FOLDER\n",
    "    DATA_FOLDER = MAIN_FOLDER + '3_ortho_irrg/3_Ortho_IRRG/top_potsdam_{}_IRRG.tif'\n",
    "    DSM_FOLDER = MAIN_FOLDER + '1_dsm/1_DSM/dsm_potsdam_0{}.tif'\n",
    "    NDSM_FOLDER = MAIN_FOLDER + '1_dsm_normalisation/1_DSM_normalisation/dsm_potsdam_0{}_normalized_lastools.jpg'\n",
    "    LABEL_FOLDER = MAIN_FOLDER + '5_labels_for_participants/5_Labels_for_participants/top_potsdam_{}_label.tif'\n",
    "    ERODED_FOLDER = MAIN_FOLDER + '5_labels_for_participants_no_boundary/5_Labels_for_participants_no_Boundary/top_potsdam_{}_label_noBoundary.tif'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a38d9cdbb61b0a0465dcf5ecc6cafeb59bfeaae9"
   },
   "outputs": [],
   "source": [
    "# ISPRS color palette\n",
    "# Let's define the standard ISPRS color palette\n",
    "\n",
    "palette = {0 : (255, 255, 255), # Impervious surfaces (white)\n",
    "           1 : (0, 0, 255),     # Buildings (blue)\n",
    "           2 : (0, 255, 255),   # Low vegetation (cyan)\n",
    "           3 : (0, 255, 0),     # Trees (green)\n",
    "           4 : (255, 255, 0),   # Cars (yellow)\n",
    "           5 : (255, 0, 0),     # Clutter (red)\n",
    "           6 : (0, 0, 0)}       # Undefined (black)\n",
    "\n",
    "invert_palette = {v: k for k, v in palette.items()}\n",
    "\n",
    "def convert_to_color(arr_2d, palette=palette):\n",
    "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
    "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = arr_2d == c\n",
    "        arr_3d[m] = i\n",
    "\n",
    "    return arr_3d\n",
    "\n",
    "def convert_from_color(arr_3d, palette=invert_palette):\n",
    "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
    "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
    "\n",
    "    for c, i in palette.items():\n",
    "        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
    "        arr_2d[m] = i\n",
    "\n",
    "    return arr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "3b27f2ea65458b7cc384fa7e79bc56dba91789c2"
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "def get_random_pos(img, window_shape):\n",
    "    \"\"\" Extract of 2D random patch of shape window_shape in the image \"\"\"\n",
    "    w, h = window_shape\n",
    "    W, H = img.shape[-2:]\n",
    "    x1 = random.randint(0, W - w - 1)\n",
    "    x2 = x1 + w\n",
    "    y1 = random.randint(0, H - h - 1)\n",
    "    y2 = y1 + h\n",
    "    return x1, x2, y1, y2\n",
    "\n",
    "def CrossEntropy2d(input, target, weight=None, size_average=True):\n",
    "    \"\"\" 2D version of the cross entropy loss \"\"\"\n",
    "    dim = input.dim()\n",
    "    if dim == 2:\n",
    "        return F.cross_entropy(input, target, weight, size_average)\n",
    "    elif dim == 4:\n",
    "        output = input.view(input.size(0),input.size(1), -1)\n",
    "        output = torch.transpose(output,1,2).contiguous()\n",
    "        output = output.view(-1,output.size(2))\n",
    "        target = target.view(-1)\n",
    "        return F.cross_entropy(output, target,weight, size_average)\n",
    "    else:\n",
    "        raise ValueError('Expected 2 or 4 dimensions (got {})'.format(dim))\n",
    "\n",
    "def accuracy(input, target):\n",
    "    return 100 * float(np.count_nonzero(input == target)) / target.size\n",
    "\n",
    "def sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Slide a window_shape window across the image with a stride of step \"\"\"\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            yield x, y, window_size[0], window_size[1]\n",
    "            \n",
    "def count_sliding_window(top, step=10, window_size=(20,20)):\n",
    "    \"\"\" Count the number of windows in an image \"\"\"\n",
    "    c = 0\n",
    "    for x in range(0, top.shape[0], step):\n",
    "        if x + window_size[0] > top.shape[0]:\n",
    "            x = top.shape[0] - window_size[0]\n",
    "        for y in range(0, top.shape[1], step):\n",
    "            if y + window_size[1] > top.shape[1]:\n",
    "                y = top.shape[1] - window_size[1]\n",
    "            c += 1\n",
    "    return c\n",
    "\n",
    "def grouper(n, iterable):\n",
    "    \"\"\" Browse an iterator by chunk of n elements \"\"\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "\n",
    "def metrics(predictions, gts, label_values=LABELS):\n",
    "    cm = confusion_matrix(\n",
    "            gts,\n",
    "            predictions,\n",
    "            range(len(label_values)))\n",
    "    \n",
    "    print(\"Confusion matrix :\")\n",
    "    print(cm)\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    # Compute global accuracy\n",
    "    total = sum(sum(cm))\n",
    "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
    "    accuracy *= 100 / float(total)\n",
    "    print(\"{} pixels processed\".format(total))\n",
    "    print(\"Total accuracy : {}%\".format(accuracy))\n",
    "    \n",
    "    print(\"---\")\n",
    "    \n",
    "    # Compute F1 score\n",
    "    F1Score = np.zeros(len(label_values))\n",
    "    for i in range(len(label_values)):\n",
    "        try:\n",
    "            F1Score[i] = 2. * cm[i,i] / (np.sum(cm[i,:]) + np.sum(cm[:,i]))\n",
    "        except:\n",
    "            # Ignore exception if there is no element in class i for test set\n",
    "            pass\n",
    "    print(\"F1Score :\")\n",
    "    for l_id, score in enumerate(F1Score):\n",
    "        print(\"{}: {}\".format(label_values[l_id], score))\n",
    "\n",
    "    print(\"---\")\n",
    "        \n",
    "    # Compute kappa coefficient\n",
    "    total = np.sum(cm)\n",
    "    pa = np.trace(cm) / float(total)\n",
    "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / float(total*total)\n",
    "    kappa = (pa - pe) / (1 - pe);\n",
    "    print(\"Kappa: \" + str(kappa))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "806064dbf5367ecca8b42065a42e3a36285ccc56"
   },
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "\n",
    "class ISPRS_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, train_ids, dsm_ids, data_files=DATA_FOLDER, label_files=LABEL_FOLDER,\n",
    "                dsm_files=DSM_FOLDER, ndsm_files=NDSM_FOLDER,\n",
    "                cache=False, augmentation=True):\n",
    "        super(ISPRS_dataset, self).__init__()\n",
    "        \n",
    "        self.augmentation = augmentation\n",
    "        self.cache = cache\n",
    "        \n",
    "        # List of files\n",
    "        self.data_files = [DATA_FOLDER.format(id) for id in train_ids]\n",
    "        self.dsm_files = [DSM_FOLDER.format(id) for id in dsm_ids]\n",
    "        self.ndsm_files = [NDSM_FOLDER.format(id) for id in dsm_ids]\n",
    "        self.label_files = [LABEL_FOLDER.format(id) for id in train_ids]\n",
    "        \n",
    "        '''\n",
    "        # Sanity check : raise an error if some files do not exist\n",
    "        for f in self.data_files + self.label_files + self.dsm_files + self.ndsm_files:\n",
    "            if not os.path.isfile(f):\n",
    "                f1 = f[:36] + '0' + f[36:]\n",
    "                if not os.path.isfile(f1):\n",
    "                    f2 = f[:64] + '0' + f[64:]\n",
    "                    if not os.path.isfile(f2):\n",
    "                        raise KeyError('{} is not a file !'.format(f2))\n",
    "        '''\n",
    "        \n",
    "        # Initialize cache dicts\n",
    "        self.data_cache_ = {}\n",
    "        self.label_cache_ = {}\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        # Default epoch size is 10000 samples\n",
    "        return 12000\n",
    "    \n",
    "    @classmethod\n",
    "    def data_augmentation(cls, *arrays, flip=True, mirror=True):\n",
    "        will_flip, will_mirror = False, False\n",
    "        if flip and random.random() < 0.5:\n",
    "            will_flip = True\n",
    "        if mirror and random.random() < 0.5:\n",
    "            will_mirror = True\n",
    "        \n",
    "        results = []\n",
    "        for array in arrays:\n",
    "            if will_flip:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[::-1, :]\n",
    "                else:\n",
    "                    array = array[:, ::-1, :]\n",
    "            if will_mirror:\n",
    "                if len(array.shape) == 2:\n",
    "                    array = array[:, ::-1]\n",
    "                else:\n",
    "                    array = array[:, :, ::-1]\n",
    "            results.append(np.copy(array))\n",
    "            \n",
    "        return tuple(results)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # Pick a random image\n",
    "        random_idx = random.randint(0, len(self.data_files) - 1)\n",
    "        \n",
    "        # If the tile hasn't been loaded yet, put in cache\n",
    "        if random_idx in self.data_cache_.keys():\n",
    "            data = self.data_cache_[random_idx]\n",
    "        else:\n",
    "            # Data is normalized in [0, 1]\n",
    "            im = np.dstack((io.imread(self.data_files[random_idx]), io.imread(self.dsm_files[random_idx])))\n",
    "            im = np.dstack((im, io.imread(self.ndsm_files[random_idx])))\n",
    "            data = 1/255 * np.asarray(im.transpose((2,0,1)), dtype='float32')\n",
    "            if self.cache:\n",
    "                self.data_cache_[random_idx] = data\n",
    "            \n",
    "        if random_idx in self.label_cache_.keys():\n",
    "            label = self.label_cache_[random_idx]\n",
    "        else: \n",
    "            # Labels are converted from RGB to their numeric values\n",
    "            label = np.asarray(convert_from_color(io.imread(self.label_files[random_idx])), dtype='int64')\n",
    "            if self.cache:\n",
    "                self.label_cache_[random_idx] = label\n",
    "\n",
    "        # Get a random patch\n",
    "        x1, x2, y1, y2 = get_random_pos(data, WINDOW_SIZE)\n",
    "        data_p = data[:, x1:x2,y1:y2]\n",
    "        label_p = label[x1:x2,y1:y2]\n",
    "        \n",
    "        # Data augmentation\n",
    "        data_p, label_p = self.data_augmentation(data_p, label_p)\n",
    "\n",
    "        # Return the torch.Tensor values\n",
    "        return (torch.from_numpy(data_p),\n",
    "                torch.from_numpy(label_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a4780be561a9f6912bcbede2051ef58fb9f31c13"
   },
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    # SegNet network\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.kaiming_normal(m.weight.data)\n",
    "    \n",
    "    def __init__(self, in_channels=IN_CHANNELS, out_channels=N_CLASSES):\n",
    "        super(SegNet, self).__init__()\n",
    "        self.pool = nn.MaxPool2d(2, return_indices=True)\n",
    "        self.unpool = nn.MaxUnpool2d(2)\n",
    "        \n",
    "        self.conv1_1 = nn.Conv2d(in_channels, 64, 3, padding=1)\n",
    "        self.conv1_1_bn = nn.BatchNorm2d(64)\n",
    "        self.conv1_2 = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1_2_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2_1 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.conv2_1_bn = nn.BatchNorm2d(128)\n",
    "        self.conv2_2 = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv2_2_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3_1 = nn.Conv2d(128, 256, 3, padding=1)\n",
    "        self.conv3_1_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_2 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_2_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_3 = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_3_bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv4_1 = nn.Conv2d(256, 512, 3, padding=1)\n",
    "        self.conv4_1_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_2_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_3_bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5_1 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_1_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_2 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_2_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_3 = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_3_bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv5_3_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_3_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_2_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_2_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv5_1_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv5_1_D_bn = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv4_3_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_3_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_2_D = nn.Conv2d(512, 512, 3, padding=1)\n",
    "        self.conv4_2_D_bn = nn.BatchNorm2d(512)\n",
    "        self.conv4_1_D = nn.Conv2d(512, 256, 3, padding=1)\n",
    "        self.conv4_1_D_bn = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv3_3_D = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_3_D_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_2_D = nn.Conv2d(256, 256, 3, padding=1)\n",
    "        self.conv3_2_D_bn = nn.BatchNorm2d(256)\n",
    "        self.conv3_1_D = nn.Conv2d(256, 128, 3, padding=1)\n",
    "        self.conv3_1_D_bn = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv2_2_D = nn.Conv2d(128, 128, 3, padding=1)\n",
    "        self.conv2_2_D_bn = nn.BatchNorm2d(128)\n",
    "        self.conv2_1_D = nn.Conv2d(128, 64, 3, padding=1)\n",
    "        self.conv2_1_D_bn = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv1_2_D = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv1_2_D_bn = nn.BatchNorm2d(64)\n",
    "        self.conv1_1_D = nn.Conv2d(64, out_channels, 3, padding=1)\n",
    "        \n",
    "        self.apply(self.weight_init)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder block 1\n",
    "        x = self.conv1_1_bn(F.relu(self.conv1_1(x)))\n",
    "        x = self.conv1_2_bn(F.relu(self.conv1_2(x)))\n",
    "        x, mask1 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 2\n",
    "        x = self.conv2_1_bn(F.relu(self.conv2_1(x)))\n",
    "        x = self.conv2_2_bn(F.relu(self.conv2_2(x)))\n",
    "        x, mask2 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 3\n",
    "        x = self.conv3_1_bn(F.relu(self.conv3_1(x)))\n",
    "        x = self.conv3_2_bn(F.relu(self.conv3_2(x)))\n",
    "        x = self.conv3_3_bn(F.relu(self.conv3_3(x)))\n",
    "        x, mask3 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 4\n",
    "        x = self.conv4_1_bn(F.relu(self.conv4_1(x)))\n",
    "        x = self.conv4_2_bn(F.relu(self.conv4_2(x)))\n",
    "        x = self.conv4_3_bn(F.relu(self.conv4_3(x)))\n",
    "        x, mask4 = self.pool(x)\n",
    "        \n",
    "        # Encoder block 5\n",
    "        x = self.conv5_1_bn(F.relu(self.conv5_1(x)))\n",
    "        x = self.conv5_2_bn(F.relu(self.conv5_2(x)))\n",
    "        x = self.conv5_3_bn(F.relu(self.conv5_3(x)))\n",
    "        x, mask5 = self.pool(x)\n",
    "        \n",
    "        # Decoder block 5\n",
    "        x = self.unpool(x, mask5)\n",
    "        x = self.conv5_3_D_bn(F.relu(self.conv5_3_D(x)))\n",
    "        x = self.conv5_2_D_bn(F.relu(self.conv5_2_D(x)))\n",
    "        x = self.conv5_1_D_bn(F.relu(self.conv5_1_D(x)))\n",
    "        \n",
    "        # Decoder block 4\n",
    "        x = self.unpool(x, mask4)\n",
    "        x = self.conv4_3_D_bn(F.relu(self.conv4_3_D(x)))\n",
    "        x = self.conv4_2_D_bn(F.relu(self.conv4_2_D(x)))\n",
    "        x = self.conv4_1_D_bn(F.relu(self.conv4_1_D(x)))\n",
    "        \n",
    "        # Decoder block 3\n",
    "        x = self.unpool(x, mask3)\n",
    "        x = self.conv3_3_D_bn(F.relu(self.conv3_3_D(x)))\n",
    "        x = self.conv3_2_D_bn(F.relu(self.conv3_2_D(x)))\n",
    "        x = self.conv3_1_D_bn(F.relu(self.conv3_1_D(x)))\n",
    "        \n",
    "        # Decoder block 2\n",
    "        x = self.unpool(x, mask2)\n",
    "        x = self.conv2_2_D_bn(F.relu(self.conv2_2_D(x)))\n",
    "        x = self.conv2_1_D_bn(F.relu(self.conv2_1_D(x)))\n",
    "        \n",
    "        # Decoder block 1\n",
    "        x = self.unpool(x, mask1)\n",
    "        x = self.conv1_2_D_bn(F.relu(self.conv1_2_D(x)))\n",
    "        x = F.log_softmax(self.conv1_1_D(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "8e48c6afec943195913b292c4786a9adf01e584b"
   },
   "outputs": [],
   "source": [
    "# instantiate the network\n",
    "net = SegNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "b95ea537bb3c483b4b590375207cc373ed65f185"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegNet(\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (conv1_1): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_3_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_3_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_2_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_2_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_1_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_3_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_3_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_2_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_2_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1_D): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_1_D_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_3_D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_3_D_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_2_D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_2_D_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1_D): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_1_D_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_2_D): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2_D_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1_D): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_1_D_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_2_D): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2_D_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_1_D): Conv2d(64, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "3094824b16216e371f3194dfd8a82e3fd98bdb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiles for training :  ['2_10', '2_11', '3_10', '4_12', '5_10', '6_7', '6_10', '7_9', '7_10']\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "if DATASET == 'Potsdam':\n",
    "    all_files = sorted(glob(LABEL_FOLDER.replace('{}', '*')))\n",
    "    # [\"_\".join(f.split('_')[3:5]) for f in all_files]\n",
    "    all_ids = [\"_\".join(f.split('_')[5:7]) for f in all_files]\n",
    "# Random tile numbers for train/test split\n",
    "train_ids = random.sample(all_ids, 2 * len(all_ids) // 3 + 1)\n",
    "test_ids = list(set(all_ids) - set(train_ids))\n",
    "\n",
    "# Exemple of a train/test split on Vaihingen :\n",
    "train_ids = ['2_10', '2_11', '3_10', '4_12', '5_10', '6_7', '6_10', '7_9', '7_10']\n",
    "dsm_ids = ['2_10', '2_11','3_10', '4_12', '5_10', '6_07', '6_10', '7_09', '7_10']\n",
    "print(\"Tiles for training : \", train_ids)\n",
    "\n",
    "train_set = ISPRS_dataset(train_ids, dsm_ids, cache=CACHE)\n",
    "train_loader = torch.utils.data.DataLoader(train_set,batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "649b42279a018c320cc93ed54cdff7c15d9a8db1"
   },
   "outputs": [],
   "source": [
    "base_lr = 0.0005\n",
    "params_dict = dict(net.named_parameters())\n",
    "params = []\n",
    "for key, value in params_dict.items():\n",
    "    if '_D' in key:\n",
    "        # Decoder weights are trained at the nominal learning rate\n",
    "        params += [{'params':[value],'lr': base_lr}]\n",
    "    else:\n",
    "        # Encoder weights are trained at lr / 2 (we have VGG-16 weights as initialization)\n",
    "        params += [{'params':[value],'lr': base_lr / 2}]\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=base_lr, weight_decay=0.005)\n",
    "# We define the scheduler\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, [10, 20, 30, 40], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "3d28773fd2cb59984d4d758993272acfe06309f4"
   },
   "outputs": [],
   "source": [
    "def dice_loss(input, target):\n",
    "    input = torch.sigmoid(input)\n",
    "    smooth = 1.0\n",
    "\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return ((2.0 * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        if not (target.size() == input.size()):\n",
    "            raise ValueError(\"Target size ({}) must be the same as input size ({})\"\n",
    "                             .format(target.size(), input.size()))\n",
    "\n",
    "        max_val = (-input).clamp(min=0)\n",
    "        loss = input - input * target + max_val + \\\n",
    "            ((-max_val).exp() + (-input - max_val).exp()).log()\n",
    "\n",
    "        invprobs = F.logsigmoid(-input * (target * 2.0 - 1.0))\n",
    "        loss = (invprobs * self.gamma).exp() * loss\n",
    "        \n",
    "        return loss.mean()\n",
    "    \n",
    "class MixedLoss(nn.Module):\n",
    "    def __init__(self, alpha, gamma):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.focal = FocalLoss(gamma)\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        loss = self.alpha*self.focal(input, target) - torch.log(dice_loss(input, target))\n",
    "        return loss.mean()\n",
    "    \n",
    "def dice(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    return 2.0 * (pred*targs).sum() / ((pred+targs).sum() + 1.0)\n",
    "\n",
    "def IoU(pred, targs):\n",
    "    pred = (pred>0).float()\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "e1c376825ae35c6e061aa74a9f97fcd7567e649b"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "def train(net, optimizer, epochs, scheduler=None, weights=WEIGHTS, save_epoch = 5):\n",
    "    losses = np.zeros(1000000)\n",
    "    mean_losses = np.zeros(100000000)\n",
    "    weights = weights.cuda()\n",
    "\n",
    "    criterion = MixedLoss(10.0, 2.0)\n",
    "    iter_ = 0\n",
    "    \n",
    "    for e in range(1, epochs + 1):\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        net.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            output = net(data)\n",
    "            loss = CrossEntropy2d(output, target, weight=weights)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses[iter_] = loss.item()\n",
    "            mean_losses[iter_] = np.mean(losses[max(0,iter_-100):iter_])\n",
    "            gc.collect()\n",
    "            if iter_ % 100 == 0:\n",
    "                clear_output()\n",
    "                #rgb = np.asarray(255 * np.transpose(data.data.cpu().numpy()[0],(1,2,0)), dtype='uint8')\n",
    "                pred = np.argmax(output.data.cpu().numpy()[0], axis=0)\n",
    "                gt = target.data.cpu().numpy()[0]\n",
    "                print('Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}'.format(\n",
    "                    e, epochs, batch_idx, len(train_loader),\n",
    "                    100. * batch_idx / len(train_loader), loss.item(), accuracy(pred, gt)))\n",
    "                plt.plot(mean_losses[:iter_]) and plt.show()\n",
    "                fig = plt.figure()\n",
    "                fig.add_subplot(131)\n",
    "                plt.imshow(convert_to_color(gt))\n",
    "                plt.title('Ground truth')\n",
    "                fig.add_subplot(132)\n",
    "                plt.title('Prediction')\n",
    "                plt.imshow(convert_to_color(pred))\n",
    "                plt.show()\n",
    "            iter_ += 1\n",
    "            \n",
    "            del(data, target, loss)\n",
    "            \n",
    "        if e % save_epoch == 0:\n",
    "            # We validate with the largest possible stride for faster computing\n",
    "            gc.collect()\n",
    "            #acc = test(net, test_ids, all=False, stride=min(WINDOW_SIZE))\n",
    "            torch.save(net.state_dict(), './segnet_epoch{}'.format(e+150))\n",
    "    torch.save(net.state_dict(), './segnet_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "eb87e761aa2d6b29b98989163c6dd97ba22ee3fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegNet(\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (unpool): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
       "  (conv1_1): Conv2d(5, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_1_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_1_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_2_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_3_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_1_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_2_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_3_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_3_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_3_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_2_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_2_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5_1_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5_1_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_3_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_3_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_2_D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_2_D_bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4_1_D): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4_1_D_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_3_D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_3_D_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_2_D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_2_D_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3_1_D): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3_1_D_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_2_D): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_2_D_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2_1_D): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2_1_D_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_2_D): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv1_2_D_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_1_D): Conv2d(64, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"../input/svgnet-2/segnet_final\"))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0b7eed3e5a288ebe5c343957b908ddf7b862d7a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (epoch 33/50) [600/1500 (40%)]\tLoss: 0.419009\tAccuracy: 99.87045599489795\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(net, optimizer, 50, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "26b0a9541ef6af94503c4aab3d1ca40b1dc0e089"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "dbb38e8f2234b1a406dbc945146bc41c86e105e6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
