{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchviz\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.9MB/s \r\n",
      "\u001b[?25hCollecting torchsummary\r\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.6/site-packages (from torchviz) (1.0.1.post2)\r\n",
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.6/site-packages (from torchviz) (0.8.4)\r\n",
      "Building wheels for collected packages: torchviz\r\n",
      "  Building wheel for torchviz (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Stored in directory: /tmp/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\r\n",
      "Successfully built torchviz\r\n",
      "Installing collected packages: torchviz, torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1 torchviz-0.0.1\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torchviz torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from glob import glob\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler\n",
    "import torch.nn.init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import os\n",
    "from torchvision import models\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 6\n",
    "IN_CHANNELS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(*models):\n",
    "    for model in models:\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "                nn.init.kaiming_normal_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    module.bias.data.zero_()\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                module.weight.data.fill_(1)\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "\n",
    "def get_upsampling_weight(in_channels, out_channels, kernel_size):\n",
    "    factor = (kernel_size + 1) // 2\n",
    "    if kernel_size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:kernel_size, :kernel_size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * (1 - abs(og[1] - center) / factor)\n",
    "    weight = np.zeros((in_channels, out_channels, kernel_size, kernel_size), dtype=np.float64)\n",
    "    weight[list(range(in_channels)), list(range(out_channels)), :, :] = filt\n",
    "    return torch.from_numpy(weight).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "d261eb0cdff5db818d4b6f4c131cfe7155ca1b33"
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, bias=False, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            shortcut = self.downsample(x)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class DeconvBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, expansion=2, stride=1, upsample=None):\n",
    "        super(DeconvBottleneck, self).__init__()\n",
    "        self.expansion = expansion\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        if stride == 1:\n",
    "            self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                                   stride=stride, bias=False, padding=1)\n",
    "        else:\n",
    "            self.conv2 = nn.ConvTranspose2d(out_channels, out_channels,\n",
    "                                            kernel_size=3,\n",
    "                                            stride=stride, bias=False,\n",
    "                                            padding=1,\n",
    "                                            output_padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion,\n",
    "                               kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.upsample = upsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        if self.upsample is not None:\n",
    "            shortcut = self.upsample(x)\n",
    "\n",
    "        out += shortcut\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, downblock, upblock, num_layers, n_classes=N_CLASSES):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(5, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.dlayer1 = self._make_downlayer(downblock, 64, num_layers[0])\n",
    "        self.dlayer2 = self._make_downlayer(downblock, 128, num_layers[1],\n",
    "                                            stride=2)\n",
    "        self.dlayer3 = self._make_downlayer(downblock, 256, num_layers[2],\n",
    "                                            stride=2)\n",
    "        self.dlayer4 = self._make_downlayer(downblock, 512, num_layers[3],\n",
    "                                            stride=2)\n",
    "\n",
    "        self.uplayer1 = self._make_up_block(upblock, 512, 1, stride=2)\n",
    "        self.uplayer2 = self._make_up_block(upblock, 256, num_layers[2], stride=2)\n",
    "        self.uplayer3 = self._make_up_block(upblock, 128, num_layers[1], stride=2)\n",
    "        self.uplayer4 = self._make_up_block(upblock, 64, 2, stride=2)\n",
    "\n",
    "        upsample = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.in_channels,  # 256\n",
    "                               64,\n",
    "                               kernel_size=1, stride=2,\n",
    "                               bias=False, output_padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "        self.uplayer_top = DeconvBottleneck(self.in_channels, 64, 1, 2, upsample)\n",
    "\n",
    "        self.conv1_1 = nn.ConvTranspose2d(64, n_classes, kernel_size=1, stride=1,\n",
    "                                 bias=False)\n",
    "\n",
    "    def _make_downlayer(self, block, init_channels, num_layer, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != init_channels * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, init_channels*block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(init_channels*block.expansion),\n",
    "            )\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, init_channels, stride, downsample))\n",
    "        self.in_channels = init_channels * block.expansion\n",
    "        for i in range(1, num_layer):\n",
    "            layers.append(block(self.in_channels, init_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _make_up_block(self, block, init_channels, num_layer, stride=1):\n",
    "        upsample = None\n",
    "        # expansion = block.expansion\n",
    "        if stride != 1 or self.in_channels != init_channels * 2:\n",
    "            upsample = nn.Sequential(\n",
    "                nn.ConvTranspose2d(self.in_channels, init_channels*2,\n",
    "                                   kernel_size=1, stride=stride,\n",
    "                                   bias=False, output_padding=1),\n",
    "                nn.BatchNorm2d(init_channels*2),\n",
    "            )\n",
    "        layers = []\n",
    "        for i in range(1, num_layer):\n",
    "            layers.append(block(self.in_channels, init_channels, 4))\n",
    "        layers.append(block(self.in_channels, init_channels, 2, stride, upsample))\n",
    "        self.in_channels = init_channels * 2\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        img = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.dlayer1(x)\n",
    "        x1 = x\n",
    "        x = self.dlayer2(x)\n",
    "        x2 = x\n",
    "        x = self.dlayer3(x)\n",
    "        x3 = x\n",
    "        x = self.dlayer4(x)\n",
    "        \n",
    "        x = self.uplayer1(x)\n",
    "        x = x + x3\n",
    "        del(x3)\n",
    "        x = self.uplayer2(x)\n",
    "        x = x + x2\n",
    "        del(x2)\n",
    "        x = self.uplayer3(x)\n",
    "        x = x + x1\n",
    "        del(x1)\n",
    "        x = self.uplayer4(x)\n",
    "        x = self.uplayer_top(x)\n",
    "        \n",
    "        x = self.conv1_1(x, output_size=img.size())\n",
    "\n",
    "        return x\n",
    "\n",
    "def FCN8s_Rn101(**kwargs):\n",
    "    return ResNet(Bottleneck, DeconvBottleneck, [3, 4, 23, 2], N_CLASSES, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "3023f2190d56f65234d0df55d6516a290e636340"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU()\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (dlayer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (dlayer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (dlayer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (dlayer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (uplayer1): Sequential(\n",
       "    (0): DeconvBottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvTranspose2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (upsample): Sequential(\n",
       "        (0): ConvTranspose2d(2048, 1024, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (uplayer2): Sequential(\n",
       "    (0): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (9): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (10): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (11): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (12): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (13): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (14): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (15): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (16): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (17): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (18): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (19): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (20): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (21): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (22): DeconvBottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvTranspose2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (upsample): Sequential(\n",
       "        (0): ConvTranspose2d(1024, 512, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (uplayer3): Sequential(\n",
       "    (0): DeconvBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): DeconvBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): DeconvBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): DeconvBottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvTranspose2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (upsample): Sequential(\n",
       "        (0): ConvTranspose2d(512, 256, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (uplayer4): Sequential(\n",
       "    (0): DeconvBottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): DeconvBottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "      (upsample): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (uplayer_top): DeconvBottleneck(\n",
       "    (conv1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1), bias=False)\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (conv3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "    (upsample): Sequential(\n",
       "      (0): ConvTranspose2d(128, 64, kernel_size=(1, 1), stride=(2, 2), output_padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv1_1): ConvTranspose2d(64, 6, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FCN8s_Rn101()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]          15,680\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5           [-1, 64, 64, 64]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 64, 64]             128\n",
      "              ReLU-7           [-1, 64, 64, 64]               0\n",
      "            Conv2d-8           [-1, 64, 64, 64]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 64, 64]             128\n",
      "             ReLU-10           [-1, 64, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
      "             ReLU-13          [-1, 256, 64, 64]               0\n",
      "           Conv2d-14          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-15          [-1, 256, 64, 64]             512\n",
      "             ReLU-16          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-17          [-1, 256, 64, 64]               0\n",
      "           Conv2d-18           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-19           [-1, 64, 64, 64]             128\n",
      "             ReLU-20           [-1, 64, 64, 64]               0\n",
      "           Conv2d-21           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-22           [-1, 64, 64, 64]             128\n",
      "             ReLU-23           [-1, 64, 64, 64]               0\n",
      "           Conv2d-24          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-25          [-1, 256, 64, 64]             512\n",
      "             ReLU-26          [-1, 256, 64, 64]               0\n",
      "             ReLU-27          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-28          [-1, 256, 64, 64]               0\n",
      "           Conv2d-29           [-1, 64, 64, 64]          16,384\n",
      "      BatchNorm2d-30           [-1, 64, 64, 64]             128\n",
      "             ReLU-31           [-1, 64, 64, 64]               0\n",
      "           Conv2d-32           [-1, 64, 64, 64]          36,864\n",
      "      BatchNorm2d-33           [-1, 64, 64, 64]             128\n",
      "             ReLU-34           [-1, 64, 64, 64]               0\n",
      "           Conv2d-35          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-36          [-1, 256, 64, 64]             512\n",
      "             ReLU-37          [-1, 256, 64, 64]               0\n",
      "             ReLU-38          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-39          [-1, 256, 64, 64]               0\n",
      "           Conv2d-40          [-1, 128, 64, 64]          32,768\n",
      "      BatchNorm2d-41          [-1, 128, 64, 64]             256\n",
      "             ReLU-42          [-1, 128, 64, 64]               0\n",
      "           Conv2d-43          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-44          [-1, 128, 32, 32]             256\n",
      "             ReLU-45          [-1, 128, 32, 32]               0\n",
      "           Conv2d-46          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-47          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-50          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-51          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-52          [-1, 512, 32, 32]               0\n",
      "           Conv2d-53          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-54          [-1, 128, 32, 32]             256\n",
      "             ReLU-55          [-1, 128, 32, 32]               0\n",
      "           Conv2d-56          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-57          [-1, 128, 32, 32]             256\n",
      "             ReLU-58          [-1, 128, 32, 32]               0\n",
      "           Conv2d-59          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-60          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-61          [-1, 512, 32, 32]               0\n",
      "             ReLU-62          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-63          [-1, 512, 32, 32]               0\n",
      "           Conv2d-64          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-65          [-1, 128, 32, 32]             256\n",
      "             ReLU-66          [-1, 128, 32, 32]               0\n",
      "           Conv2d-67          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-68          [-1, 128, 32, 32]             256\n",
      "             ReLU-69          [-1, 128, 32, 32]               0\n",
      "           Conv2d-70          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-71          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-72          [-1, 512, 32, 32]               0\n",
      "             ReLU-73          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-74          [-1, 512, 32, 32]               0\n",
      "           Conv2d-75          [-1, 128, 32, 32]          65,536\n",
      "      BatchNorm2d-76          [-1, 128, 32, 32]             256\n",
      "             ReLU-77          [-1, 128, 32, 32]               0\n",
      "           Conv2d-78          [-1, 128, 32, 32]         147,456\n",
      "      BatchNorm2d-79          [-1, 128, 32, 32]             256\n",
      "             ReLU-80          [-1, 128, 32, 32]               0\n",
      "           Conv2d-81          [-1, 512, 32, 32]          65,536\n",
      "      BatchNorm2d-82          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-83          [-1, 512, 32, 32]               0\n",
      "             ReLU-84          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-85          [-1, 512, 32, 32]               0\n",
      "           Conv2d-86          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-87          [-1, 256, 32, 32]             512\n",
      "             ReLU-88          [-1, 256, 32, 32]               0\n",
      "           Conv2d-89          [-1, 256, 16, 16]         589,824\n",
      "      BatchNorm2d-90          [-1, 256, 16, 16]             512\n",
      "             ReLU-91          [-1, 256, 16, 16]               0\n",
      "           Conv2d-92         [-1, 1024, 16, 16]         262,144\n",
      "      BatchNorm2d-93         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-94         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-95         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-96         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-97         [-1, 1024, 16, 16]               0\n",
      "       Bottleneck-98         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-99          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-100          [-1, 256, 16, 16]             512\n",
      "            ReLU-101          [-1, 256, 16, 16]               0\n",
      "          Conv2d-102          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-103          [-1, 256, 16, 16]             512\n",
      "            ReLU-104          [-1, 256, 16, 16]               0\n",
      "          Conv2d-105         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-106         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-107         [-1, 1024, 16, 16]               0\n",
      "            ReLU-108         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-109         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-110          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-111          [-1, 256, 16, 16]             512\n",
      "            ReLU-112          [-1, 256, 16, 16]               0\n",
      "          Conv2d-113          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-114          [-1, 256, 16, 16]             512\n",
      "            ReLU-115          [-1, 256, 16, 16]               0\n",
      "          Conv2d-116         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-117         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-118         [-1, 1024, 16, 16]               0\n",
      "            ReLU-119         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-121          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 16, 16]             512\n",
      "            ReLU-123          [-1, 256, 16, 16]               0\n",
      "          Conv2d-124          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 16, 16]             512\n",
      "            ReLU-126          [-1, 256, 16, 16]               0\n",
      "          Conv2d-127         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-129         [-1, 1024, 16, 16]               0\n",
      "            ReLU-130         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-131         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-132          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-133          [-1, 256, 16, 16]             512\n",
      "            ReLU-134          [-1, 256, 16, 16]               0\n",
      "          Conv2d-135          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-136          [-1, 256, 16, 16]             512\n",
      "            ReLU-137          [-1, 256, 16, 16]               0\n",
      "          Conv2d-138         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-139         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-140         [-1, 1024, 16, 16]               0\n",
      "            ReLU-141         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-142         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-143          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-144          [-1, 256, 16, 16]             512\n",
      "            ReLU-145          [-1, 256, 16, 16]               0\n",
      "          Conv2d-146          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-147          [-1, 256, 16, 16]             512\n",
      "            ReLU-148          [-1, 256, 16, 16]               0\n",
      "          Conv2d-149         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-150         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-151         [-1, 1024, 16, 16]               0\n",
      "            ReLU-152         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-153         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-154          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-155          [-1, 256, 16, 16]             512\n",
      "            ReLU-156          [-1, 256, 16, 16]               0\n",
      "          Conv2d-157          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-158          [-1, 256, 16, 16]             512\n",
      "            ReLU-159          [-1, 256, 16, 16]               0\n",
      "          Conv2d-160         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-161         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-162         [-1, 1024, 16, 16]               0\n",
      "            ReLU-163         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-164         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-165          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-166          [-1, 256, 16, 16]             512\n",
      "            ReLU-167          [-1, 256, 16, 16]               0\n",
      "          Conv2d-168          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-169          [-1, 256, 16, 16]             512\n",
      "            ReLU-170          [-1, 256, 16, 16]               0\n",
      "          Conv2d-171         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-172         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-173         [-1, 1024, 16, 16]               0\n",
      "            ReLU-174         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-175         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-176          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-177          [-1, 256, 16, 16]             512\n",
      "            ReLU-178          [-1, 256, 16, 16]               0\n",
      "          Conv2d-179          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-180          [-1, 256, 16, 16]             512\n",
      "            ReLU-181          [-1, 256, 16, 16]               0\n",
      "          Conv2d-182         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-183         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-184         [-1, 1024, 16, 16]               0\n",
      "            ReLU-185         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-186         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-187          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-188          [-1, 256, 16, 16]             512\n",
      "            ReLU-189          [-1, 256, 16, 16]               0\n",
      "          Conv2d-190          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-191          [-1, 256, 16, 16]             512\n",
      "            ReLU-192          [-1, 256, 16, 16]               0\n",
      "          Conv2d-193         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-194         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-195         [-1, 1024, 16, 16]               0\n",
      "            ReLU-196         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-197         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-198          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-199          [-1, 256, 16, 16]             512\n",
      "            ReLU-200          [-1, 256, 16, 16]               0\n",
      "          Conv2d-201          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-202          [-1, 256, 16, 16]             512\n",
      "            ReLU-203          [-1, 256, 16, 16]               0\n",
      "          Conv2d-204         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-205         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-206         [-1, 1024, 16, 16]               0\n",
      "            ReLU-207         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-208         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-209          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-210          [-1, 256, 16, 16]             512\n",
      "            ReLU-211          [-1, 256, 16, 16]               0\n",
      "          Conv2d-212          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-213          [-1, 256, 16, 16]             512\n",
      "            ReLU-214          [-1, 256, 16, 16]               0\n",
      "          Conv2d-215         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-216         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-217         [-1, 1024, 16, 16]               0\n",
      "            ReLU-218         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-219         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-220          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-221          [-1, 256, 16, 16]             512\n",
      "            ReLU-222          [-1, 256, 16, 16]               0\n",
      "          Conv2d-223          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-224          [-1, 256, 16, 16]             512\n",
      "            ReLU-225          [-1, 256, 16, 16]               0\n",
      "          Conv2d-226         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-227         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-228         [-1, 1024, 16, 16]               0\n",
      "            ReLU-229         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-230         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-231          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 16, 16]             512\n",
      "            ReLU-233          [-1, 256, 16, 16]               0\n",
      "          Conv2d-234          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 16, 16]             512\n",
      "            ReLU-236          [-1, 256, 16, 16]               0\n",
      "          Conv2d-237         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-239         [-1, 1024, 16, 16]               0\n",
      "            ReLU-240         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-241         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-242          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-243          [-1, 256, 16, 16]             512\n",
      "            ReLU-244          [-1, 256, 16, 16]               0\n",
      "          Conv2d-245          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-246          [-1, 256, 16, 16]             512\n",
      "            ReLU-247          [-1, 256, 16, 16]               0\n",
      "          Conv2d-248         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-249         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-250         [-1, 1024, 16, 16]               0\n",
      "            ReLU-251         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-252         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-253          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-254          [-1, 256, 16, 16]             512\n",
      "            ReLU-255          [-1, 256, 16, 16]               0\n",
      "          Conv2d-256          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-257          [-1, 256, 16, 16]             512\n",
      "            ReLU-258          [-1, 256, 16, 16]               0\n",
      "          Conv2d-259         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-260         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-261         [-1, 1024, 16, 16]               0\n",
      "            ReLU-262         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-263         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-264          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-265          [-1, 256, 16, 16]             512\n",
      "            ReLU-266          [-1, 256, 16, 16]               0\n",
      "          Conv2d-267          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-268          [-1, 256, 16, 16]             512\n",
      "            ReLU-269          [-1, 256, 16, 16]               0\n",
      "          Conv2d-270         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-271         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-272         [-1, 1024, 16, 16]               0\n",
      "            ReLU-273         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-274         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-275          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-276          [-1, 256, 16, 16]             512\n",
      "            ReLU-277          [-1, 256, 16, 16]               0\n",
      "          Conv2d-278          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-279          [-1, 256, 16, 16]             512\n",
      "            ReLU-280          [-1, 256, 16, 16]               0\n",
      "          Conv2d-281         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-282         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-283         [-1, 1024, 16, 16]               0\n",
      "            ReLU-284         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-285         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-286          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-287          [-1, 256, 16, 16]             512\n",
      "            ReLU-288          [-1, 256, 16, 16]               0\n",
      "          Conv2d-289          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-290          [-1, 256, 16, 16]             512\n",
      "            ReLU-291          [-1, 256, 16, 16]               0\n",
      "          Conv2d-292         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-293         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-294         [-1, 1024, 16, 16]               0\n",
      "            ReLU-295         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-296         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-297          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-298          [-1, 256, 16, 16]             512\n",
      "            ReLU-299          [-1, 256, 16, 16]               0\n",
      "          Conv2d-300          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-301          [-1, 256, 16, 16]             512\n",
      "            ReLU-302          [-1, 256, 16, 16]               0\n",
      "          Conv2d-303         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-304         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-305         [-1, 1024, 16, 16]               0\n",
      "            ReLU-306         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-307         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-308          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-309          [-1, 256, 16, 16]             512\n",
      "            ReLU-310          [-1, 256, 16, 16]               0\n",
      "          Conv2d-311          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-312          [-1, 256, 16, 16]             512\n",
      "            ReLU-313          [-1, 256, 16, 16]               0\n",
      "          Conv2d-314         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-315         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-316         [-1, 1024, 16, 16]               0\n",
      "            ReLU-317         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-318         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-319          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-320          [-1, 256, 16, 16]             512\n",
      "            ReLU-321          [-1, 256, 16, 16]               0\n",
      "          Conv2d-322          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-323          [-1, 256, 16, 16]             512\n",
      "            ReLU-324          [-1, 256, 16, 16]               0\n",
      "          Conv2d-325         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-326         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-327         [-1, 1024, 16, 16]               0\n",
      "            ReLU-328         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-329         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-330          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-331          [-1, 256, 16, 16]             512\n",
      "            ReLU-332          [-1, 256, 16, 16]               0\n",
      "          Conv2d-333          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-334          [-1, 256, 16, 16]             512\n",
      "            ReLU-335          [-1, 256, 16, 16]               0\n",
      "          Conv2d-336         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-337         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-338         [-1, 1024, 16, 16]               0\n",
      "            ReLU-339         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-340         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-341          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-342          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-343          [-1, 512, 16, 16]               0\n",
      "          Conv2d-344            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-345            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-346            [-1, 512, 8, 8]               0\n",
      "          Conv2d-347           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-348           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-349           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-350           [-1, 2048, 8, 8]       2,097,152\n",
      "     BatchNorm2d-351           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-352           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-353           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-354            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-355            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-356            [-1, 512, 8, 8]               0\n",
      "          Conv2d-357            [-1, 512, 8, 8]       2,359,296\n",
      "     BatchNorm2d-358            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-359            [-1, 512, 8, 8]               0\n",
      "          Conv2d-360           [-1, 2048, 8, 8]       1,048,576\n",
      "     BatchNorm2d-361           [-1, 2048, 8, 8]           4,096\n",
      "            ReLU-362           [-1, 2048, 8, 8]               0\n",
      "            ReLU-363           [-1, 2048, 8, 8]               0\n",
      "      Bottleneck-364           [-1, 2048, 8, 8]               0\n",
      "          Conv2d-365            [-1, 512, 8, 8]       1,048,576\n",
      "     BatchNorm2d-366            [-1, 512, 8, 8]           1,024\n",
      "            ReLU-367            [-1, 512, 8, 8]               0\n",
      " ConvTranspose2d-368          [-1, 512, 16, 16]       2,359,296\n",
      "     BatchNorm2d-369          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-370          [-1, 512, 16, 16]               0\n",
      "          Conv2d-371         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-372         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-373         [-1, 1024, 16, 16]               0\n",
      " ConvTranspose2d-374         [-1, 1024, 16, 16]       2,097,152\n",
      "     BatchNorm2d-375         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-376         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-377         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-378          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-379          [-1, 256, 16, 16]             512\n",
      "            ReLU-380          [-1, 256, 16, 16]               0\n",
      "          Conv2d-381          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-382          [-1, 256, 16, 16]             512\n",
      "            ReLU-383          [-1, 256, 16, 16]               0\n",
      "          Conv2d-384         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-385         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-386         [-1, 1024, 16, 16]               0\n",
      "            ReLU-387         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-388         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-389          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-390          [-1, 256, 16, 16]             512\n",
      "            ReLU-391          [-1, 256, 16, 16]               0\n",
      "          Conv2d-392          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-393          [-1, 256, 16, 16]             512\n",
      "            ReLU-394          [-1, 256, 16, 16]               0\n",
      "          Conv2d-395         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-396         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-397         [-1, 1024, 16, 16]               0\n",
      "            ReLU-398         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-399         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-400          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-401          [-1, 256, 16, 16]             512\n",
      "            ReLU-402          [-1, 256, 16, 16]               0\n",
      "          Conv2d-403          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-404          [-1, 256, 16, 16]             512\n",
      "            ReLU-405          [-1, 256, 16, 16]               0\n",
      "          Conv2d-406         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-407         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-408         [-1, 1024, 16, 16]               0\n",
      "            ReLU-409         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-410         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-411          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 16, 16]             512\n",
      "            ReLU-413          [-1, 256, 16, 16]               0\n",
      "          Conv2d-414          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 16, 16]             512\n",
      "            ReLU-416          [-1, 256, 16, 16]               0\n",
      "          Conv2d-417         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-419         [-1, 1024, 16, 16]               0\n",
      "            ReLU-420         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-421         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-422          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-423          [-1, 256, 16, 16]             512\n",
      "            ReLU-424          [-1, 256, 16, 16]               0\n",
      "          Conv2d-425          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-426          [-1, 256, 16, 16]             512\n",
      "            ReLU-427          [-1, 256, 16, 16]               0\n",
      "          Conv2d-428         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-429         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-430         [-1, 1024, 16, 16]               0\n",
      "            ReLU-431         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-432         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-433          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-434          [-1, 256, 16, 16]             512\n",
      "            ReLU-435          [-1, 256, 16, 16]               0\n",
      "          Conv2d-436          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-437          [-1, 256, 16, 16]             512\n",
      "            ReLU-438          [-1, 256, 16, 16]               0\n",
      "          Conv2d-439         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-440         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-441         [-1, 1024, 16, 16]               0\n",
      "            ReLU-442         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-443         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-444          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-445          [-1, 256, 16, 16]             512\n",
      "            ReLU-446          [-1, 256, 16, 16]               0\n",
      "          Conv2d-447          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-448          [-1, 256, 16, 16]             512\n",
      "            ReLU-449          [-1, 256, 16, 16]               0\n",
      "          Conv2d-450         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-451         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-452         [-1, 1024, 16, 16]               0\n",
      "            ReLU-453         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-454         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-455          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-456          [-1, 256, 16, 16]             512\n",
      "            ReLU-457          [-1, 256, 16, 16]               0\n",
      "          Conv2d-458          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-459          [-1, 256, 16, 16]             512\n",
      "            ReLU-460          [-1, 256, 16, 16]               0\n",
      "          Conv2d-461         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-462         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-463         [-1, 1024, 16, 16]               0\n",
      "            ReLU-464         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-465         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-466          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-467          [-1, 256, 16, 16]             512\n",
      "            ReLU-468          [-1, 256, 16, 16]               0\n",
      "          Conv2d-469          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-470          [-1, 256, 16, 16]             512\n",
      "            ReLU-471          [-1, 256, 16, 16]               0\n",
      "          Conv2d-472         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-473         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-474         [-1, 1024, 16, 16]               0\n",
      "            ReLU-475         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-476         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-477          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-478          [-1, 256, 16, 16]             512\n",
      "            ReLU-479          [-1, 256, 16, 16]               0\n",
      "          Conv2d-480          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-481          [-1, 256, 16, 16]             512\n",
      "            ReLU-482          [-1, 256, 16, 16]               0\n",
      "          Conv2d-483         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-484         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-485         [-1, 1024, 16, 16]               0\n",
      "            ReLU-486         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-487         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-488          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-489          [-1, 256, 16, 16]             512\n",
      "            ReLU-490          [-1, 256, 16, 16]               0\n",
      "          Conv2d-491          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-492          [-1, 256, 16, 16]             512\n",
      "            ReLU-493          [-1, 256, 16, 16]               0\n",
      "          Conv2d-494         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-495         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-496         [-1, 1024, 16, 16]               0\n",
      "            ReLU-497         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-498         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-499          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-500          [-1, 256, 16, 16]             512\n",
      "            ReLU-501          [-1, 256, 16, 16]               0\n",
      "          Conv2d-502          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-503          [-1, 256, 16, 16]             512\n",
      "            ReLU-504          [-1, 256, 16, 16]               0\n",
      "          Conv2d-505         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-506         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-507         [-1, 1024, 16, 16]               0\n",
      "            ReLU-508         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-509         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-510          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-511          [-1, 256, 16, 16]             512\n",
      "            ReLU-512          [-1, 256, 16, 16]               0\n",
      "          Conv2d-513          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-514          [-1, 256, 16, 16]             512\n",
      "            ReLU-515          [-1, 256, 16, 16]               0\n",
      "          Conv2d-516         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-517         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-518         [-1, 1024, 16, 16]               0\n",
      "            ReLU-519         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-520         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-521          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-522          [-1, 256, 16, 16]             512\n",
      "            ReLU-523          [-1, 256, 16, 16]               0\n",
      "          Conv2d-524          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-525          [-1, 256, 16, 16]             512\n",
      "            ReLU-526          [-1, 256, 16, 16]               0\n",
      "          Conv2d-527         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-528         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-529         [-1, 1024, 16, 16]               0\n",
      "            ReLU-530         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-531         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-532          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-533          [-1, 256, 16, 16]             512\n",
      "            ReLU-534          [-1, 256, 16, 16]               0\n",
      "          Conv2d-535          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-536          [-1, 256, 16, 16]             512\n",
      "            ReLU-537          [-1, 256, 16, 16]               0\n",
      "          Conv2d-538         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-539         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-540         [-1, 1024, 16, 16]               0\n",
      "            ReLU-541         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-542         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-543          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-544          [-1, 256, 16, 16]             512\n",
      "            ReLU-545          [-1, 256, 16, 16]               0\n",
      "          Conv2d-546          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-547          [-1, 256, 16, 16]             512\n",
      "            ReLU-548          [-1, 256, 16, 16]               0\n",
      "          Conv2d-549         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-550         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-551         [-1, 1024, 16, 16]               0\n",
      "            ReLU-552         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-553         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-554          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-555          [-1, 256, 16, 16]             512\n",
      "            ReLU-556          [-1, 256, 16, 16]               0\n",
      "          Conv2d-557          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-558          [-1, 256, 16, 16]             512\n",
      "            ReLU-559          [-1, 256, 16, 16]               0\n",
      "          Conv2d-560         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-561         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-562         [-1, 1024, 16, 16]               0\n",
      "            ReLU-563         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-564         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-565          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-566          [-1, 256, 16, 16]             512\n",
      "            ReLU-567          [-1, 256, 16, 16]               0\n",
      "          Conv2d-568          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-569          [-1, 256, 16, 16]             512\n",
      "            ReLU-570          [-1, 256, 16, 16]               0\n",
      "          Conv2d-571         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-572         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-573         [-1, 1024, 16, 16]               0\n",
      "            ReLU-574         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-575         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-576          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-577          [-1, 256, 16, 16]             512\n",
      "            ReLU-578          [-1, 256, 16, 16]               0\n",
      "          Conv2d-579          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-580          [-1, 256, 16, 16]             512\n",
      "            ReLU-581          [-1, 256, 16, 16]               0\n",
      "          Conv2d-582         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-583         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-584         [-1, 1024, 16, 16]               0\n",
      "            ReLU-585         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-586         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-587          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-588          [-1, 256, 16, 16]             512\n",
      "            ReLU-589          [-1, 256, 16, 16]               0\n",
      "          Conv2d-590          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-591          [-1, 256, 16, 16]             512\n",
      "            ReLU-592          [-1, 256, 16, 16]               0\n",
      "          Conv2d-593         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-594         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-595         [-1, 1024, 16, 16]               0\n",
      "            ReLU-596         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-597         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-598          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-599          [-1, 256, 16, 16]             512\n",
      "            ReLU-600          [-1, 256, 16, 16]               0\n",
      "          Conv2d-601          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-602          [-1, 256, 16, 16]             512\n",
      "            ReLU-603          [-1, 256, 16, 16]               0\n",
      "          Conv2d-604         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-605         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-606         [-1, 1024, 16, 16]               0\n",
      "            ReLU-607         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-608         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-609          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-610          [-1, 256, 16, 16]             512\n",
      "            ReLU-611          [-1, 256, 16, 16]               0\n",
      "          Conv2d-612          [-1, 256, 16, 16]         589,824\n",
      "     BatchNorm2d-613          [-1, 256, 16, 16]             512\n",
      "            ReLU-614          [-1, 256, 16, 16]               0\n",
      "          Conv2d-615         [-1, 1024, 16, 16]         262,144\n",
      "     BatchNorm2d-616         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-617         [-1, 1024, 16, 16]               0\n",
      "            ReLU-618         [-1, 1024, 16, 16]               0\n",
      "DeconvBottleneck-619         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-620          [-1, 256, 16, 16]         262,144\n",
      "     BatchNorm2d-621          [-1, 256, 16, 16]             512\n",
      "            ReLU-622          [-1, 256, 16, 16]               0\n",
      " ConvTranspose2d-623          [-1, 256, 32, 32]         589,824\n",
      "     BatchNorm2d-624          [-1, 256, 32, 32]             512\n",
      "            ReLU-625          [-1, 256, 32, 32]               0\n",
      "          Conv2d-626          [-1, 512, 32, 32]         131,072\n",
      "     BatchNorm2d-627          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-628          [-1, 512, 32, 32]               0\n",
      " ConvTranspose2d-629          [-1, 512, 32, 32]         524,288\n",
      "     BatchNorm2d-630          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-631          [-1, 512, 32, 32]               0\n",
      "DeconvBottleneck-632          [-1, 512, 32, 32]               0\n",
      "          Conv2d-633          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-634          [-1, 128, 32, 32]             256\n",
      "            ReLU-635          [-1, 128, 32, 32]               0\n",
      "          Conv2d-636          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-637          [-1, 128, 32, 32]             256\n",
      "            ReLU-638          [-1, 128, 32, 32]               0\n",
      "          Conv2d-639          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-640          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-641          [-1, 512, 32, 32]               0\n",
      "            ReLU-642          [-1, 512, 32, 32]               0\n",
      "DeconvBottleneck-643          [-1, 512, 32, 32]               0\n",
      "          Conv2d-644          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-645          [-1, 128, 32, 32]             256\n",
      "            ReLU-646          [-1, 128, 32, 32]               0\n",
      "          Conv2d-647          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-648          [-1, 128, 32, 32]             256\n",
      "            ReLU-649          [-1, 128, 32, 32]               0\n",
      "          Conv2d-650          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-651          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-652          [-1, 512, 32, 32]               0\n",
      "            ReLU-653          [-1, 512, 32, 32]               0\n",
      "DeconvBottleneck-654          [-1, 512, 32, 32]               0\n",
      "          Conv2d-655          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-656          [-1, 128, 32, 32]             256\n",
      "            ReLU-657          [-1, 128, 32, 32]               0\n",
      "          Conv2d-658          [-1, 128, 32, 32]         147,456\n",
      "     BatchNorm2d-659          [-1, 128, 32, 32]             256\n",
      "            ReLU-660          [-1, 128, 32, 32]               0\n",
      "          Conv2d-661          [-1, 512, 32, 32]          65,536\n",
      "     BatchNorm2d-662          [-1, 512, 32, 32]           1,024\n",
      "            ReLU-663          [-1, 512, 32, 32]               0\n",
      "            ReLU-664          [-1, 512, 32, 32]               0\n",
      "DeconvBottleneck-665          [-1, 512, 32, 32]               0\n",
      "          Conv2d-666          [-1, 128, 32, 32]          65,536\n",
      "     BatchNorm2d-667          [-1, 128, 32, 32]             256\n",
      "            ReLU-668          [-1, 128, 32, 32]               0\n",
      " ConvTranspose2d-669          [-1, 128, 64, 64]         147,456\n",
      "     BatchNorm2d-670          [-1, 128, 64, 64]             256\n",
      "            ReLU-671          [-1, 128, 64, 64]               0\n",
      "          Conv2d-672          [-1, 256, 64, 64]          32,768\n",
      "     BatchNorm2d-673          [-1, 256, 64, 64]             512\n",
      "            ReLU-674          [-1, 256, 64, 64]               0\n",
      " ConvTranspose2d-675          [-1, 256, 64, 64]         131,072\n",
      "     BatchNorm2d-676          [-1, 256, 64, 64]             512\n",
      "            ReLU-677          [-1, 256, 64, 64]               0\n",
      "DeconvBottleneck-678          [-1, 256, 64, 64]               0\n",
      "          Conv2d-679           [-1, 64, 64, 64]          16,384\n",
      "     BatchNorm2d-680           [-1, 64, 64, 64]             128\n",
      "            ReLU-681           [-1, 64, 64, 64]               0\n",
      "          Conv2d-682           [-1, 64, 64, 64]          36,864\n",
      "     BatchNorm2d-683           [-1, 64, 64, 64]             128\n",
      "            ReLU-684           [-1, 64, 64, 64]               0\n",
      "          Conv2d-685          [-1, 256, 64, 64]          16,384\n",
      "     BatchNorm2d-686          [-1, 256, 64, 64]             512\n",
      "            ReLU-687          [-1, 256, 64, 64]               0\n",
      "            ReLU-688          [-1, 256, 64, 64]               0\n",
      "DeconvBottleneck-689          [-1, 256, 64, 64]               0\n",
      "          Conv2d-690           [-1, 64, 64, 64]          16,384\n",
      "     BatchNorm2d-691           [-1, 64, 64, 64]             128\n",
      "            ReLU-692           [-1, 64, 64, 64]               0\n",
      " ConvTranspose2d-693         [-1, 64, 128, 128]          36,864\n",
      "     BatchNorm2d-694         [-1, 64, 128, 128]             128\n",
      "            ReLU-695         [-1, 64, 128, 128]               0\n",
      "          Conv2d-696        [-1, 128, 128, 128]           8,192\n",
      "     BatchNorm2d-697        [-1, 128, 128, 128]             256\n",
      "            ReLU-698        [-1, 128, 128, 128]               0\n",
      " ConvTranspose2d-699        [-1, 128, 128, 128]          32,768\n",
      "     BatchNorm2d-700        [-1, 128, 128, 128]             256\n",
      "            ReLU-701        [-1, 128, 128, 128]               0\n",
      "DeconvBottleneck-702        [-1, 128, 128, 128]               0\n",
      "          Conv2d-703         [-1, 64, 128, 128]           8,192\n",
      "     BatchNorm2d-704         [-1, 64, 128, 128]             128\n",
      "            ReLU-705         [-1, 64, 128, 128]               0\n",
      " ConvTranspose2d-706         [-1, 64, 256, 256]          36,864\n",
      "     BatchNorm2d-707         [-1, 64, 256, 256]             128\n",
      "            ReLU-708         [-1, 64, 256, 256]               0\n",
      "          Conv2d-709         [-1, 64, 256, 256]           4,096\n",
      "     BatchNorm2d-710         [-1, 64, 256, 256]             128\n",
      "            ReLU-711         [-1, 64, 256, 256]               0\n",
      " ConvTranspose2d-712         [-1, 64, 256, 256]           8,192\n",
      "     BatchNorm2d-713         [-1, 64, 256, 256]             128\n",
      "            ReLU-714         [-1, 64, 256, 256]               0\n",
      "DeconvBottleneck-715         [-1, 64, 256, 256]               0\n",
      " ConvTranspose2d-716          [-1, 6, 256, 256]             384\n",
      "================================================================\n",
      "Total params: 71,609,920\n",
      "Trainable params: 71,609,920\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.25\n",
      "Forward/backward pass size (MB): 1673.00\n",
      "Params size (MB): 273.17\n",
      "Estimated Total Size (MB): 1947.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(net, input_size=(5, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9112663269042969"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1,20):\n",
    "    x = Variable(torch.randn(1, 5, 256, 256)).cuda()\n",
    "    out = net(x)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "elapsed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 256, 256])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
